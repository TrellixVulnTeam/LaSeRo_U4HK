{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_output_generation.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"euVM0pt-w0Xs","colab_type":"code","colab":{}},"source":["#!tar -xzvf  /content/drive/My\\ Drive/LC82121112013339LGN00.tar\n","training_set_path='/content/drive/My Drive/Metadata/train.txt'\n","val_set_path='/content/drive/My Drive/Metadata/val.txt'\n","test_set_path='/content/drive/My Drive/Metadata/test.txt'\n","model_path='/content/drive/My Drive/models/'\n","\n","num_classes=2\n","image_shape=(512,512,9)\n","padding=((0,0),(0,0))\n","batch_size=5 # num of chunks\n","epochs=10\n","\n","train_subset_size = 2000 \n","val_subset_size = 500\n","n_splits = 1\n","set_info={ \n","          2:[0,1,2,3,4,5,6,8,9]}\n","          \n","\n","training_set_size=2000\n","val_set_size=500\n","test_set_size=899\n","optimizer='sgd' # can try adam .... prop\n","loss_function='categorical_crossentropy'\n","metrics=['accuracy']  # can add more metrics\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yP4Xqz1UzR2_","colab_type":"code","colab":{}},"source":["from keras.layers import Activation,BatchNormalization,Conv2D\n","from keras.engine.topology import Layer\n","#import keras.backend as K\n","#import tensorflow as tf\n","import keras.backend.tensorflow_backend as K\n","\n","class MaxPoolingWithIndices(Layer):\n","    def __init__(self, pool_size,strides,padding='SAME',**kwargs):\n","        super(MaxPoolingWithIndices, self).__init__(**kwargs)\n","        self.pool_size=pool_size\n","        self.strides=strides\n","        self.padding=padding\n","        return\n","    def call(self,x):\n","        pool_size=self.pool_size\n","        strides=self.strides\n","        if isinstance(pool_size,int):\n","            ps=[1,pool_size,pool_size,1]\n","        else:\n","            ps=[1,pool_size[0],pool_size[1],1]\n","        if isinstance(strides,int):\n","            st=[1,strides,strides,1]\n","        else:\n","            st=[1,strides[0],strides[1],1]\n","        output1,output2=K.tf.nn.max_pool_with_argmax(x,ps,st,self.padding)\n","        return [output1,output2]\n","    def compute_output_shape(self, input_shape):\n","        if isinstance(self.pool_size,int):\n","            output_shape=(input_shape[0],input_shape[1]//self.pool_size,input_shape[2]//self.pool_size,input_shape[3])\n","        else:\n","            output_shape=(input_shape[0],input_shape[1]//self.pool_size[0],input_shape[2]//self.pool_size[1],input_shape[3])\n","        return [output_shape,output_shape]\n","\n","\n","class UpSamplingWithIndices(Layer):\n","    def __init__(self, **kwargs):\n","        super(UpSamplingWithIndices, self).__init__(**kwargs)\n","        return\n","    def call(self,x):\n","        argmax=K.cast(K.flatten(x[1]),'int32')\n","        max_value=K.flatten(x[0])\n","        with K.tf.variable_scope(self.name):\n","            input_shape=K.shape(x[0])\n","            batch_size=input_shape[0]\n","            image_size=input_shape[1]*input_shape[2]*input_shape[3]\n","            output_shape=[input_shape[0],input_shape[1]*2,input_shape[2]*2,input_shape[3]]\n","            indices_0=K.flatten(K.tf.matmul(K.reshape(K.tf.range(batch_size),(batch_size,1)),K.ones((1,image_size),dtype='int32')))\n","            indices_1=argmax%(image_size*4)//(output_shape[2]*output_shape[3])\n","            indices_2=argmax%(output_shape[2]*output_shape[3])//output_shape[3]\n","            indices_3=argmax%output_shape[3]\n","            indices=K.tf.stack([indices_0,indices_1,indices_2,indices_3])\n","            output=K.tf.scatter_nd(K.transpose(indices),max_value,output_shape)\n","            return output\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0][0],input_shape[0][1]*2,input_shape[0][2]*2,input_shape[0][3]\n","\n","def CompositeConv(inputs,num_layers,num_features):\n","    output=inputs\n","    if isinstance(num_features,int):\n","        for i in range(num_layers):\n","            output=Conv2D(num_features,(7,7),padding='same')(output)\n","            output=BatchNormalization(axis=3)(output)\n","            output=Activation('relu')(output)\n","        return output\n","    for i in range(num_layers):\n","        output=Conv2D(num_features[i],(7,7),padding='same')(output)\n","        output=BatchNormalization(axis=3)(output)\n","        output=Activation('relu')(output)\n","    return output\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qaQqjULrfKGA","colab_type":"code","outputId":"21e913c8-a2d3-4e60-bb39-f2ab906b0c21","executionInfo":{"status":"ok","timestamp":1573680190930,"user_tz":300,"elapsed":257,"user":{"displayName":"whereare therocks","photoUrl":"","userId":"11641855154344275890"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BXX_mRWz1gDQ","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","from keras.layers import Activation,Input,ZeroPadding2D,Cropping2D\n","\n","\n","def create_model():\n","    inputs=Input(shape=image_shape)\n","\n","    x = ZeroPadding2D(padding)(inputs)\n","\n","    x=CompositeConv(x,2,64)\n","    x,argmax1=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","    \n","    x=CompositeConv(x,2,64)\n","    x,argmax2=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","    \n","    x=CompositeConv(x,3,64)\n","    x,argmax3=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","    x=CompositeConv(x,3,64)\n","    x,argmax4=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","    x=CompositeConv(x,3,64)\n","    x,argmax5=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","    x=UpSamplingWithIndices()([x,argmax5])\n","    x=CompositeConv(x,3,64)\n","\n","    x=UpSamplingWithIndices()([x,argmax4])\n","    x=CompositeConv(x,3,64)\n","\n","    x=UpSamplingWithIndices()([x,argmax3])\n","    x=CompositeConv(x,3,64)\n","\n","    x=UpSamplingWithIndices()([x,argmax2])\n","    x=CompositeConv(x,2,64)\n","    \n","    x=UpSamplingWithIndices()([x,argmax1])\n","    x=CompositeConv(x,2,[64,num_classes])\n","\n","    x=Activation('softmax')(x)\n","\n","    y=Cropping2D(padding)(x)\n","    my_model=Model(inputs=inputs,outputs=y)\n","    \n","    return my_model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_XmrvXys1i8p","colab_type":"code","colab":{}},"source":["import imageio\n","import numpy as np\n","from keras.utils import to_categorical\n","\n","\n","def read_image_batch(image_list, batch_size, channel_list):\n","    while True:\n","        l=len(image_list)\n","        num_batch=l//batch_size\n","        if num_batch*batch_size<l:\n","            num_batch+=1\n","        for i in range(num_batch):\n","           \n","            batch_set=image_list[batch_size*i:min(batch_size*(i+1),l),:]\n","            batch_set=[batch_set[bs] for bs in range(len(batch_set))]\n","            X=np.array([np.load(line[0][0:]) for line in batch_set])\n","            labels=np.array([np.load(line[1][0:]) for line in batch_set])\n","            y=to_categorical(labels,num_classes)\n","            X = X[:, :, :, channel_list]\n","            yield tuple((X, y))\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"M4xxKPSslDwg","colab_type":"code","colab":{}},"source":["test_names=[]\n","\n","with open(test_set_path,\"r\") as f:\n","  test_image_list=[]\n","  for line in f.readlines():\n","    arr=[]\n","    str_array=line.split(\" \")\n","    arr.append(str_array[0]+\" \"+str_array[1])\n","    arr.append(str_array[2]+\" \"+str_array[3][:-1])\n","    test_image_list.append(arr)\n","    test_names.append(line)\n","\n","test_image_list=np.asarray(test_image_list)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"my-pI2L4smKf","colab_type":"code","colab":{}},"source":["import imageio\n","import numpy as np\n","from keras.utils import to_categorical\n","\n","'''\n","def read_test_image_batch(data_path,batch_size,channel):\n","  image_list=[]\n","  with open(data_path,\"r\") as f:\n","    for line in f.readlines():\n","      arr=[]\n","      str_array=line.split(\" \")\n","      arr.append(str_array[0]+\" \"+str_array[1])\n","      arr.append(str_array[2]+\" \"+str_array[3][:-1])\n","      image_list.append(arr)\n","  image_list=np.asarray(image_list)\n"," \n","  \n","  while True: \n","    l=len(image_list)\n","    num_batch=l//batch_size\n","    if num_batch*batch_size<l:\n","        num_batch+=1\n","       \n","    for i in range(num_batch):\n","      batch_set=image_list[batch_size*i:min(batch_size*(i+1),l),:]\n","      batch_set=[batch_set[bs] for bs in range(len(batch_set))]\n","      X=np.array([np.load(line[0][0:]) for line in batch_set])\n","      X=X[:,:,:,channel]\n","      labels=np.array([np.load(line[1][0:]) for line in batch_set])\n","      y=to_categorical(labels,num_classes)\n","      \n","      yield tuple((X, y))\n","'''\n","\n","def read_test_image_batch(image_list, batch_size, channel_list):\n","    while True:\n","        l = len(image_list)\n","        num_batch = l // batch_size\n","        if num_batch*batch_size<l:\n","            num_batch+=1\n","        for i in range(num_batch):\n","            batch_set=image_list[batch_size*i:min(batch_size*(i+1),l),:]\n","            batch_set=[batch_set[bs] for bs in range(len(batch_set))]\n","            X=np.array([np.load(line[0][0:]) for line in batch_set])\n","            labels=np.array([np.load(line[1][0:]) for line in batch_set])\n","            y=to_categorical(labels,num_classes)\n","            X = X[:, :, :, channel_list]\n","            yield tuple((X, y))\n","  \n","\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqPh_qNx47ca","colab_type":"code","outputId":"2b7b83d1-0f89-4d33-dadf-6645c8e74847","executionInfo":{"status":"ok","timestamp":1573680340855,"user_tz":300,"elapsed":148588,"user":{"displayName":"whereare therocks","photoUrl":"","userId":"11641855154344275890"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["import argparse\n","from keras.models import Model\n","from keras.layers import Activation,Input\n","from scipy.stats import mode\n","import os\n","\n","import argparse\n","from keras.models import Model\n","from keras.layers import Activation,Input\n","from scipy.stats import mode\n","import os\n","import time\n","#from custom_layers import MaxPoolingWithIndices,UpSamplingWithIndices,CompositeConv\n","#import config as cf\n","#from util import read_image_batch\n","#from create_model import create_model\n","tic = time.time()\n","print(\"start time: {}\".format(tic))\n","class_labels=[]\n","model_name = \"model_rich_feature_0\"\n","current_model = os.path.join(model_path, model_name)\n","assert os.path.exists(current_model)\n","toc = time.time()\n","\n","test_data=read_test_image_batch(test_image_list,batch_size,set_info[2])\n","\n","toc = time.time() - toc\n","print(\"test_data loaded in {1:.2f} seconds\\ntotal runtime: {1:.2f}\".format(toc, time.time() - tic))\n","\n","my_model=create_model()\n","toc = time.time() - toc\n","print(\"model created in {1:.2f} seconds\\ntotal runtime: {1:.2f}\".format(toc, time.time() - tic))\n","\n","my_model.compile(optimizer,loss=loss_function,metrics=metrics)\n","toc = time.time() - toc\n","print(\"model compiled in {1:.2f} seconds\\ntotal runtime: {1:.2f}\".format(toc, time.time() - tic))\n","\n","my_model.load_weights(current_model)\n","toc = time.time() - toc\n","print(\"weights loaded in {1:.2f} seconds\\ntotal runtime: {1:.2f}\".format(toc, time.time() - tic))\n","\n","\n","probs=my_model.predict(test_data,steps=(test_set_size+1)//batch_size)\n","toc = time.time() - toc\n","print(\"predictions generated in {1:.2f} seconds\\ntotal runtime: {1:.2f}\".format(toc, time.time() - tic))\n","\n","class_labels.append(probs.argmax(axis=-1))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["start time: 1573680193.172696\n","test_data loaded in 0.00 seconds\n","total runtime: 0.00\n","model created in 3.09 seconds\n","total runtime: 3.09\n","model compiled in 3.13 seconds\n","total runtime: 3.13\n","weights loaded in 11.98 seconds\n","total runtime: 11.98\n","predictions generated in 146.93 seconds\n","total runtime: 146.93\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QeYlI-ejEzGu","colab_type":"code","colab":{}},"source":["import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9p1-4eU9El8y","colab_type":"code","colab":{}},"source":["output = class_labels[0]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZU30-vqEtEk","colab_type":"code","outputId":"8231e26a-a255-4013-db3c-1e59360421ce","executionInfo":{"status":"ok","timestamp":1573680362441,"user_tz":300,"elapsed":5838,"user":{"displayName":"whereare therocks","photoUrl":"","userId":"11641855154344275890"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(output.shape)\n","hist = np.histogram(output, bins=3)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(899, 512, 512)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q9rVVw_DE5dz","colab_type":"code","outputId":"232b1e91-6416-46d7-cec3-3b2dde686021","executionInfo":{"status":"ok","timestamp":1573680362441,"user_tz":300,"elapsed":3298,"user":{"displayName":"whereare therocks","photoUrl":"","userId":"11641855154344275890"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(hist)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(array([214368380,         0,  21299076]), array([0.        , 0.33333333, 0.66666667, 1.        ]))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1FCS7jmbZc7a","colab_type":"code","outputId":"01db5e04-d16a-4051-a340-ad0620b0585d","executionInfo":{"status":"ok","timestamp":1573680368550,"user_tz":300,"elapsed":301,"user":{"displayName":"whereare therocks","photoUrl":"","userId":"11641855154344275890"}},"colab":{"base_uri":"https://localhost:8080/","height":127}},"source":["test_scene_dir = \"/content/drive/My Drive/test_chunks\"\n","output_dir = \"/content/drive/My Drive/output\"\n","\n","if not os.path.exists(os.path.join(output_dir, model_name)):\n","  os.mkdir(os.path.join(output_dir, model_name))\n","\n","test_scene_ids = [i for i in os.listdir(test_scene_dir) if os.path.isdir(os.path.join(test_scene_dir, i))]\n","print(test_scene_ids)\n","for i in test_scene_ids:\n","  output_scene_dir = os.path.join(output_dir, model_name, i)\n","  if not os.path.exists(output_scene_dir):\n","    os.mkdir(output_scene_dir)\n","    print(\"output_dir made at {}\".format(output_scene_dir))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['LC82201072015017LGN00', 'LC82071182013336LGN00', 'LC81431082013352LGN00', 'LC81681112014002LGN00', 'LC80631112014002LGN00']\n","output_dir made at /content/drive/My Drive/output/model_rich_feature_0/LC82201072015017LGN00\n","output_dir made at /content/drive/My Drive/output/model_rich_feature_0/LC82071182013336LGN00\n","output_dir made at /content/drive/My Drive/output/model_rich_feature_0/LC81431082013352LGN00\n","output_dir made at /content/drive/My Drive/output/model_rich_feature_0/LC81681112014002LGN00\n","output_dir made at /content/drive/My Drive/output/model_rich_feature_0/LC80631112014002LGN00\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7hQEymTU5DI9","colab_type":"code","outputId":"a19e2c75-1835-4ad1-8d27-259b4fb84b53","executionInfo":{"status":"ok","timestamp":1573681018426,"user_tz":300,"elapsed":643947,"user":{"displayName":"whereare therocks","photoUrl":"","userId":"11641855154344275890"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["class_labels=np.asarray(class_labels)\n","print(class_labels.shape)\n","\n","u,indices=np.unique(class_labels,return_inverse=True)\n","final_labels=u[np.argmax(np.apply_along_axis(np.bincount,0,indices.reshape(class_labels.shape),None,np.max(indices)+1),axis=0)]\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(1, 899, 512, 512)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gWguGLXbctS7","colab_type":"code","colab":{}},"source":["print(\"final labels\")\n","print(final_labels.shape)\n","\n","for i in range(test_set_size):\n","    line=test_names[i]\n","    print(line)\n","    str_array=line.split(\" \")\n","    scene_id=str_array[1][18:40]\n","    out_str=str_array[1][40:-4]+\"_output.npy\"\n","    print(out_str)\n","    print(\"\\nsaved to:\")\n","    print(os.path.join(output_dir, model_name, scene_id, out_str))\n","    np.save(os.path.join(output_dir, model_name, scene_id, out_str),final_labels[i])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"55indsfD1s5J","colab_type":"code","colab":{}},"source":["import argparse\n","from keras.utils import multi_gpu_model\n","from keras.models import Model\n","from keras.layers import Activation,Input\n","\n","\n","\n","def getSubsets(data_path, set_info, subset_size):\n","  image_list=[]\n","  with open(data_path,\"r\") as f:\n","    for line in f.readlines():\n","      arr=[]\n","      str_array=line.split(\" \")\n","      arr.append(str_array[0]+\" \"+str_array[1])\n","      arr.append(str_array[2]+\" \"+str_array[3][:-1])\n","      image_list.append(arr)\n","\n","    image_list = np.asarray(image_list)\n","    np.random.seed(1)\n","    np.random.shuffle(image_list)\n","    data = []\n","    jump = int(subset_size - ((subset_size*n_splits)-image_list.shape[0])/2)\n","    for i in range(0, image_list.shape[0]-subset_size, jump):\n","      #arr = np.random.randint(0, len(image_list), subset_size)\n","      #subset = image_list[arr,]\n","      subset = image_list[i: i+subset_size,]\n","      for key, value in set_info.items():        \n","          data.append(read_image_batch(subset, batch_size, value))\n","           \n","  return np.asarray(data)\n","            \n","\n","def main(args):\n","    #make_segnet_input_file('/content/drive/My Drive',['LC82121112013339LGN00'],'/content/drive/My Drive/Metadata/train.txt')\n","    \n","    train_data = getSubsets(training_set_path, set_info, train_subset_size)\n","    val_data = getSubsets(val_set_path, set_info, val_subset_size)\n","  \n","    key=1\n","    for i in range(1, len(train_data)):\n","      my_model=create_model()\n","      my_model.compile(optimizer,loss=loss_function,metrics=metrics)\n","      if args['resume']:\n","        my_model.load_weights(model_path+args['load']+\"_\"+str(i)+\"_key_\"+str(key))\n","      min_loss = 1.0\n","      for j in range(epochs):\n","        hist = my_model.fit_generator(train_data[i],\n","                                steps_per_epoch=(train_subset_size+1)//batch_size,\n","                                epochs=1,validation_data=val_data[i],\n","                                validation_steps=(val_subset_size+1)//batch_size)\n","        val_loss = hist.history[\"val_loss\"]\n","        print(val_loss)\n","        if val_loss[0] < min_loss:\n","          min_loss = val_loss[0]\n","          my_model.save_weights(model_path+args['save']+\"_\"+str(i)+\"_key_\"+str(key))\n","        print(\"model fit epoch: \"+str(j))\n","        #my_model.save_weights(model_path+args['save']+\"_\"+str(i)+\"_key_\"+str(key))\n","     \n","      \n","    \n","#parser = argparse.ArgumentParser()\n","#parser.add_argument(\"--save\",default='my_model')\n","#parser.add_argument(\"--resume\",action='store_true')\n","#parser.add_argument(\"--load\",default='my_model')\n","args = {\"save\": \"model_B\", \"resume\":False, \"load\": \"model_B\"}\n","# main(args)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BW4Mjj1a-mY6","colab_type":"code","outputId":"39565d57-e3bb-4cb2-80f6-3ec3c1cbf534","executionInfo":{"status":"error","timestamp":1573661198622,"user_tz":480,"elapsed":9194,"user":{"displayName":"whereare therocks","photoUrl":"","userId":"11641855154344275890"}},"colab":{"base_uri":"https://localhost:8080/","height":512}},"source":["import argparse\n","from keras.models import Model\n","from keras.layers import Activation,Input\n","from scipy.stats import mode\n","import os\n","#from custom_layers import MaxPoolingWithIndices,UpSamplingWithIndices,CompositeConv\n","#import config as cf\n","#from util import read_image_batch\n","#from create_model import create_model\n","\n","class_labels=[]\n","\n","\n","for i in os.listdir(model_path):\n","  if(i==\".ipynb_checkpoints\"):\n","    continue\n","  print(model_path+i)\n","  my_model=create_model()\n","  my_model.compile(optimizer,loss=loss_function,metrics=metrics)\n","  my_model.load_weights(model_path+i)\n","  key=int(i[-1:])\n","  if(key!=0):\n","    continue\n","  test_data=read_test_image_batch(test_set_path,batch_size,set_info[key])\n","  \n","  probs=my_model.predict(test_data,steps=(test_set_size+1)//batch_size)\n","  \n","  class_labels.append(probs.argmax(axis=-1))\n","  \n","  \n","class_labels=np.asarray(class_labels)\n","print(class_labels.shape)\n","\n","\n","\n","u,indices=np.unique(class_labels,return_inverse=True)\n","final_labels=u[np.argmax(np.apply_along_axis(np.bincount,0,indices.reshape(class_labels.shape),None,np.max(indices)+1),axis=0)]\n","\n","print(\"final labels\")\n","print(final_labels.shape)\n","#print(\"\\n\\n\")\n","#print(final_labels)\n","\n","\n","for i in range(test_set_size):\n","  line=test_names[i]\n","  print(line)\n","  str_array=line.split(\" \")\n","  scene_id=str_array[1][18:40]\n","  out_str=str_array[1][40:-4]+\"_output.npy\"\n","  print(out_str)\n","  np.save('/content/drive/My Drive/new_test_outputs_key_1/'+scene_id+out_str,final_labels[i])\n","  \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/models/model_B_2_key_1\n","/content/drive/My Drive/models/model_rich_feature_0\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1606\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1607\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Dimension 0 in both shapes must be equal, but are 7 and 64. Shapes are [7,7,5,64] and [64,9,7,7]. for 'Assign_625' (op: 'Assign') with input shapes: [7,7,5,64], [64,9,7,7].","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-32f7a1b20895>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0mmy_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m   \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mload_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m                 saving.load_weights_from_hdf5_group(\n\u001b[0;32m-> 1217\u001b[0;31m                     f, self.layers, reshape=reshape)\n\u001b[0m\u001b[1;32m   1218\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'close'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers, reshape)\u001b[0m\n\u001b[1;32m   1197\u001b[0m                              ' elements.')\n\u001b[1;32m   1198\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2725\u001b[0m                 assign_placeholder = tf.placeholder(tf_dtype,\n\u001b[1;32m   2726\u001b[0m                                                     shape=value.shape)\n\u001b[0;32m-> 2727\u001b[0;31m                 \u001b[0massign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2728\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_placeholder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_placeholder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assign_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/variables.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   2065\u001b[0m     \"\"\"\n\u001b[1;32m   2066\u001b[0m     assign = state_ops.assign(\n\u001b[0;32m-> 2067\u001b[0;31m         self._variable, value, use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m   2068\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m    225\u001b[0m     return gen_state_ops.assign(\n\u001b[1;32m    226\u001b[0m         \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_locking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         validate_shape=validate_shape)\n\u001b[0m\u001b[1;32m    228\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_state_ops.py\u001b[0m in \u001b[0;36massign\u001b[0;34m(ref, value, validate_shape, use_locking, name)\u001b[0m\n\u001b[1;32m     64\u001b[0m   _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m     65\u001b[0m         \u001b[0;34m\"Assign\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                   use_locking=use_locking, name=name)\n\u001b[0m\u001b[1;32m     67\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    792\u001b[0m         op = g.create_op(op_type_name, inputs, dtypes=None, name=scope,\n\u001b[1;32m    793\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# Conditionally invoke tfdbg v2's op callback(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3355\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input #%d is not a tensor: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m     return self._create_op_internal(op_type, inputs, dtypes, input_types, name,\n\u001b[0;32m-> 3357\u001b[0;31m                                     attrs, op_def, compute_device)\n\u001b[0m\u001b[1;32m   3358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3359\u001b[0m   def _create_op_internal(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3424\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3425\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3426\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3427\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3428\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1768\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1769\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1770\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1771\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1608\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1609\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1610\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1612\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Dimension 0 in both shapes must be equal, but are 7 and 64. Shapes are [7,7,5,64] and [64,9,7,7]. for 'Assign_625' (op: 'Assign') with input shapes: [7,7,5,64], [64,9,7,7]."]}]},{"cell_type":"code","metadata":{"id":"JqdvLZbJJ5Qi","colab_type":"code","colab":{}},"source":["import os\n","\n","\n","\"\"\"\n","This script takes a list of scene ids and creates a file that can be used as input for a segnet model\n","@param string chunk_dir: The abspath base directory where each set of chunks for a scene has its own dir named with its sceneID\n","@param list scene_ids: A list of sceneIDs that exist in the chunk_dir. The chunks of these scenes will be used in the file.\n","@param string out_path: The abspath where the resulting file should be saved.\n","@return int lines_written: the total number of lines (corresponding to a data and label chunk path) in the file.\n","file format:\n","/path/to/scene_chunk.npy /path/to/scene_chunk_label.npy\n","/path/to/scene_chunk.npy /path/to/scene_chunk_label.npy\n","/path/to/scene_chunk.npy /path/to/scene_chunk_label.npy\n","...\n","\"\"\"\n","\n","def make_segnet_input_file(chunk_dir, scene_ids, out_path):\n","    existing_scenes = [i for i in os.listdir(chunk_dir) if os.path.isdir(os.path.join(chunk_dir, i))]\n","    # filter out ids that don't exist in the given dir\n","    scene_ids = [i for i in scene_ids if i in existing_scenes]\n","    print(scene_ids)\n","\n","    lines_to_write = []\n","\n","    for i in scene_ids:\n","        scene_dir = os.path.join(chunk_dir, i)\n","        for j in os.listdir(scene_dir):\n","            if j[-9:] != \"label.npy\":\n","                data_path = os.path.join(scene_dir, j)\n","                file_split = os.path.splitext(j)\n","                label_path = os.path.join(scene_dir, file_split[0] + \"_label\" + file_split[1])\n","\n","                lines_to_write.append(\"{} {}\\n\".format(data_path, label_path))\n","\n","    with open(out_path, 'w+') as output:\n","        output.writelines(lines_to_write)\n","\n","    return len(lines_to_write)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ntm1iFciogKi","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
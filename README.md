# LaSeRo
## Landsat 8 Segmentation of Rock Outcrops

This is a research framework for geospatial analysis of Landsat 8 imagery. 

### Repository components
The framework consists of two sets of components. The first set of components make up
a data-preprocessing pipeline that is designed to prepare Landsat 8 imagery of Antarctica
for training with a Segnet semantic segmentation model. 

### The pre-processing steps are:
1. Download Landsat 8 scenes using tools from [landsat-utils](https://github.com/developmentseed/landsat-util).
 **This repository is due to be deprecated soon. We are only using a single component of it, so we have included that component directly in this repository in [this directory](https://github.com/selkind/LaSeRo/tree/master/data_preprocessing/landsat_download)**
2. (Optional) Correct the raw DN values and brightness temperature values in each scene to TOA reflectance
and TOA brightness temperature values using the formulae described [here](https://www.usgs.gov/land-resources/nli/landsat/using-usgs-landsat-level-1-data-product)
3. Generate labels for each Landsat scene by converting feature shapefiles into raster layers. A tool to burn shapefile features into a raster that has the same spatial extent of any downloaded scene. These rasterized features serve as labels of the Segnet training data. The rasterize function is located in data_preprocessing/utils/raster_tools.py
4. Combine all band TIFs from a scene into a stacked numpy array and break the stack and label layer into chunks of 512 X 512 pixels and save them as pickled .npy files. A function to do this step is in data_preprocessing/utils/raster_tools.py.

#### Once the scenes are stacked and chunked into .npy files, they are ready for model training.

### The training steps are:
1. Generate a model data text file that contains all paths to the chunks that will be used for training. This text file is generated by iterating over the stacked chunk and label directory and saving a stack, label pair on each line separated by a space (" "). **This should be refactored to csv or JSON soon for easier file creation/modification**
  - Two model data text files need to be generated for each model iteration. One for training chunks, one for validation chunks.
  - Examples of these data files are available in the metadata/ directory.
  - The last cell in colab_notebooks/model_SegNet_bands_all_data_1percent.ipynb contains a function that can be used to generate a data text file.
2. Configure the model input shape and hyper-parameters in the configuration cell of the model notebook.
  - The model configuration that yielded the best results so far is in colab_notebooks/model_SegNet_bands_all_data_1percent.ipynb
  - The key parameters that must set correctly and consistently for the model to run are the set_info, image_shape, training_set_size, and val_set_size.
  - The paths to the training and validation data, as well as the saved weights are saved in the first 4 paths. test_set_path is not necessary because we have a custom model testing procedure due to our limited ground-truth data.
3. Train the model
  -after 11 epochs, model weights are saved every 5 epochs. This is to mitigate wasted training time due to Google Colab frequently disconnecting runtimes.
  - After every epoch, the validation loss is checked against the minimum validation loss of the training session. If it is lower than the current minimum, the weights of that epoch are saved as a "best-case" model.
  - Model weights are saved according to a specific schema: "model_{bandcombination}_{epoch#}\_lr\_{learningratevalue}". ex: "model_allBands_epoch40_lr_0.01"
  
  #### A trained model must be evaluated for accuracy by comparing outputs to the ground truth layers created and provided by Burton-Johnson et. al., 2016
  
### The model evaluation steps are:

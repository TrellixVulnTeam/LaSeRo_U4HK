{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_segnet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BZ80yyThVsON","colab_type":"text"},"source":["#Configuration Parameters"]},{"cell_type":"code","metadata":{"id":"AKJ0WYEK39xn","colab_type":"code","outputId":"d2977e49-b389-4d0e-e2c6-4e612fa570a6","executionInfo":{"status":"ok","timestamp":1589568199451,"user_tz":240,"elapsed":360,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qWRDYCBmLAOq","colab_type":"code","outputId":"1bc24c6f-7865-4439-ecb7-e4b9691dd321","executionInfo":{"status":"ok","timestamp":1589568201883,"user_tz":240,"elapsed":1854,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import sys\n","import os\n","import argparse\n","import csv\n","\n","import imageio\n","import numpy as np\n","\n","from keras.utils import multi_gpu_model, to_categorical\n","from keras.layers import Activation,Input\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n","from tensorflow import convert_to_tensor\n","\n","sys.path.append(\"/content/drive/My Drive/tf-keras-SegNet\")\n","from model import segnet"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"n4k2qGbmHZ47","colab_type":"code","colab":{}},"source":["base_dir = \"/content/drive/My Drive/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"anRxznYgHeAV","colab_type":"code","colab":{}},"source":["def create_session_paths(session_name, overwrite=False, base_dir='/content/drive/My Drive/'):\n","    models_dir = os.path.join(base_dir, \"models\")\n","    session_dir = os.path.join(models_dir, session_name)\n","    # Prevent accidental overwriting of previous sessions\n","    try:\n","        os.mkdir(session_dir)\n","    except FileExistsError:\n","        if not overwrite:\n","            print(\"Set overwrite to True if you wish to continue\")\n","            raise FileExistsError\n","        print(\"overwriting session\")\n","\n","    model = os.path.join(session_dir, \"model.h5\")\n","    history = os.path.join(session_dir, \"history.json\")\n","    training_log = os.path.join(session_dir, \"logs.csv\")\n","    training_config = os.path.join(session_dir, \"config.json\")\n","    classification_report = os.path.join(session_dir, \"classification_report.txt\")\n","    return {\"model\": model,\n","            \"history\": history,\n","            \"logs\": training_log,\n","            \"config\": training_config,\n","            \"classification_report\": classification_report}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oy2LMxNpHslq","colab_type":"code","outputId":"f77ef973-12c8-4e56-b8ff-efeb4b325c97","executionInfo":{"status":"ok","timestamp":1589568203873,"user_tz":240,"elapsed":737,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["session_name = \"one_percent_transfer\"\n","session_paths = create_session_paths(session_name, overwrite=True)"],"execution_count":5,"outputs":[{"output_type":"stream","text":["overwriting session\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VFdNPyi-H98O","colab_type":"code","outputId":"f11c6e31-ef84-48e8-f230-5aae0cb77748","executionInfo":{"status":"ok","timestamp":1589568203874,"user_tz":240,"elapsed":402,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["for i in session_paths:\n","    print(session_paths[i])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/models/one_percent_transfer/model.h5\n","/content/drive/My Drive/models/one_percent_transfer/history.json\n","/content/drive/My Drive/models/one_percent_transfer/logs.csv\n","/content/drive/My Drive/models/one_percent_transfer/config.json\n","/content/drive/My Drive/models/one_percent_transfer/classification_report.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M9idtsPKSejQ","colab_type":"code","colab":{}},"source":["def get_image_list(metadata_file_path):\n","    with open(metadata_file_path, 'r') as f:\n","        return [i for i in csv.reader(f) if i]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"euVM0pt-w0Xs","colab_type":"code","colab":{}},"source":["training_set_path = '/content/drive/My Drive/Metadata/one_percent_train.csv'\n","val_set_path = '/content/drive/My Drive/Metadata/one_percent_val.csv'\n","test_set_path = '/content/drive/My Drive/Metadata/one_percent_test.csv'\n","model_path = session_paths[\"model\"]\n","\n","n_splits = 1\n","bands = [2, 3, 4] # number of bands\n","\n","num_classes = 2\n","image_shape = (512, 512, len(bands))\n","padding = ((0, 0), (0, 0))\n","batch_size = 5\n","epochs = 50\n","learning_rate = 0.02\n","\n","training_set_list = get_image_list(training_set_path)\n","val_set_list = get_image_list(val_set_path)\n","\n","training_set_size = len(training_set_list)\n","val_set_size = len(val_set_list)\n","\n","loss_function = 'categorical_crossentropy'\n","metrics = ['accuracy']\n","callback_metric = \"val_accuracy\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mCwSixkLDTkN","colab_type":"text"},"source":["# Load segnet and vgg model\n"]},{"cell_type":"code","metadata":{"id":"IR10DGtCLo10","colab_type":"code","outputId":"cb2cd245-90ec-4804-a406-1cb616fceb94","executionInfo":{"status":"ok","timestamp":1589568208546,"user_tz":240,"elapsed":2499,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["segnet_model = segnet(image_shape, num_classes)\n","vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=image_shape, classes=num_classes)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Build enceder done..\n","Build decoder done..\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qtQn_aCnaDsB","colab_type":"code","outputId":"c90f012b-6b97-416b-86dc-1231d2751e6d","executionInfo":{"status":"ok","timestamp":1589568209566,"user_tz":240,"elapsed":228,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["seg_layer_names = [i for i in segnet_model.layers if \"conv\" in i.name]\n","vgg_layer_names = [i for i in vgg_model.layers if \"conv\" in i.name]\n","\n","transferable_layer_names = {}\n","for i in range(len(vgg_layer_names)):\n","    transferable_layer_names[seg_layer_names[i].name] = vgg_layer_names[i]\n","\n","layer_count = 0\n","for i in segnet_model.layers:\n","    try:\n","        i.set_weights(transferable_layer_names[i.name].get_weights())\n","        layer_count += 1\n","    except KeyError:\n","        pass\n","\n","print(layer_count)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["13\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jS01ZdNVDXjJ","colab_type":"text"},"source":["# Transfer weights of matching layers from image-net trained vgg16 to segnet"]},{"cell_type":"markdown","metadata":{"id":"h2NZIihQWBxg","colab_type":"text"},"source":["#Training model \n"]},{"cell_type":"code","metadata":{"id":"55indsfD1s5J","colab_type":"code","colab":{}},"source":["def data_gen(metadata_file_path, bands, batch_size):\n","    image_list = np.asarray(get_image_list(metadata_file_path))\n","    np.random.seed(1)\n","    np.random.shuffle(image_list)\n","\n","    band_normalization_map = []\n","    counter = 0\n","\n","    total_steps = image_list.shape[0] // batch_size\n","    while True:\n","        step_start = counter * batch_size\n","        step_end = step_start + batch_size\n","        images = []\n","        masks = []\n","        for j in range(step_start, step_end):\n","            images.append(np.load(image_list[j, 0])[:,:,bands])\n","            masks.append(np.load(image_list[j, 1]))\n","\n","        y = to_categorical(np.array(masks))\n","        yield np.array(images), y.reshape((batch_size, y.shape[1] * y.shape[2], y.shape[3]))\n","\n","        counter +=1\n","\n","        if counter >= total_steps:\n","            counter = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SMKEnOm3E8f7","colab_type":"code","outputId":"dbc91f24-cc6b-45c0-dc5f-6b9e023d5d22","executionInfo":{"status":"ok","timestamp":1589571957693,"user_tz":240,"elapsed":3645698,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train_data = data_gen(training_set_path, bands, batch_size)\n","val_data = data_gen(val_set_path, bands, batch_size)\n","\n","segnet_model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss_function, metrics=metrics)\n","\n","checkpoint = ModelCheckpoint(session_paths[\"model\"],\n","                             monitor=callback_metric,\n","                             verbose=1,\n","                             save_best_only=True,\n","                             mode='max')\n","\n","reduce_lr = ReduceLROnPlateau(monitor=callback_metric,\n","                              factor=0.5,\n","                              patience=3,\n","                              verbose=1,\n","                              mode='max',\n","                              min_lr=0.0001)\n","\n","csv_logger = CSVLogger(session_paths[\"logs\"])\n","\n","early_stopper = EarlyStopping(monitor=callback_metric,\n","                              patience=9,\n","                              verbose=1,\n","                              mode='max')\n","\n","callbacks_list = [checkpoint, reduce_lr, csv_logger, early_stopper]\n","\n","try:\n","    model = multi_gpu_model(model)\n","except:\n","    print(\"single GPU in use\")\n","\n","hist = segnet_model.fit(train_data,\n","                        steps_per_epoch=training_set_size // batch_size,\n","                        epochs=epochs,\n","                        validation_data=val_data,\n","                        validation_steps=val_set_size // batch_size,\n","                        verbose=1,\n","                        callbacks=callbacks_list)\n","\n","val_loss = hist.history[\"val_loss\"]"],"execution_count":12,"outputs":[{"output_type":"stream","text":["single GPU in use\n","Epoch 1/50\n","154/154 [==============================] - 713s 5s/step - loss: 0.3133 - accuracy: 0.9213 - val_loss: 0.3188 - val_accuracy: 0.9196\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.91962, saving model to /content/drive/My Drive/models/one_percent_transfer/model.h5\n","Epoch 2/50\n","154/154 [==============================] - 188s 1s/step - loss: 0.1996 - accuracy: 0.9253 - val_loss: 0.1020 - val_accuracy: 0.9196\n","\n","Epoch 00002: val_accuracy improved from 0.91962 to 0.91963, saving model to /content/drive/My Drive/models/one_percent_transfer/model.h5\n","Epoch 3/50\n","154/154 [==============================] - 188s 1s/step - loss: 0.1893 - accuracy: 0.9262 - val_loss: 0.1235 - val_accuracy: 0.9141\n","\n","Epoch 00003: val_accuracy did not improve from 0.91963\n","Epoch 4/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1810 - accuracy: 0.9267 - val_loss: 0.1266 - val_accuracy: 0.9177\n","\n","Epoch 00004: val_accuracy did not improve from 0.91963\n","\n","Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.009999999776482582.\n","Epoch 5/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1742 - accuracy: 0.9283 - val_loss: 0.1227 - val_accuracy: 0.9191\n","\n","Epoch 00005: val_accuracy did not improve from 0.91963\n","Epoch 6/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1737 - accuracy: 0.9279 - val_loss: 0.1203 - val_accuracy: 0.9196\n","\n","Epoch 00006: val_accuracy did not improve from 0.91963\n","Epoch 7/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1717 - accuracy: 0.9281 - val_loss: 0.1364 - val_accuracy: 0.9195\n","\n","Epoch 00007: val_accuracy did not improve from 0.91963\n","\n","Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n","Epoch 8/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1688 - accuracy: 0.9286 - val_loss: 0.1385 - val_accuracy: 0.9198\n","\n","Epoch 00008: val_accuracy improved from 0.91963 to 0.91976, saving model to /content/drive/My Drive/models/one_percent_transfer/model.h5\n","Epoch 9/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1654 - accuracy: 0.9292 - val_loss: 0.1515 - val_accuracy: 0.9133\n","\n","Epoch 00009: val_accuracy did not improve from 0.91976\n","Epoch 10/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1667 - accuracy: 0.9292 - val_loss: 0.1676 - val_accuracy: 0.9048\n","\n","Epoch 00010: val_accuracy did not improve from 0.91976\n","Epoch 11/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1658 - accuracy: 0.9296 - val_loss: 0.1660 - val_accuracy: 0.9031\n","\n","Epoch 00011: val_accuracy did not improve from 0.91976\n","\n","Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n","Epoch 12/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1659 - accuracy: 0.9311 - val_loss: 0.1586 - val_accuracy: 0.9078\n","\n","Epoch 00012: val_accuracy did not improve from 0.91976\n","Epoch 13/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1648 - accuracy: 0.9327 - val_loss: 0.1438 - val_accuracy: 0.9178\n","\n","Epoch 00013: val_accuracy did not improve from 0.91976\n","Epoch 14/50\n","154/154 [==============================] - 187s 1s/step - loss: 0.1834 - accuracy: 0.9300 - val_loss: 0.1213 - val_accuracy: 0.9197\n","\n","Epoch 00014: val_accuracy did not improve from 0.91976\n","\n","Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n","Epoch 15/50\n","154/154 [==============================] - 186s 1s/step - loss: 0.1627 - accuracy: 0.9338 - val_loss: 0.1286 - val_accuracy: 0.9183\n","\n","Epoch 00015: val_accuracy did not improve from 0.91976\n","Epoch 16/50\n","154/154 [==============================] - 186s 1s/step - loss: 0.1598 - accuracy: 0.9347 - val_loss: 0.1348 - val_accuracy: 0.9177\n","\n","Epoch 00016: val_accuracy did not improve from 0.91976\n","Epoch 17/50\n","154/154 [==============================] - 186s 1s/step - loss: 0.1570 - accuracy: 0.9353 - val_loss: 0.1354 - val_accuracy: 0.9178\n","\n","Epoch 00017: val_accuracy did not improve from 0.91976\n","\n","Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0006249999860301614.\n","Epoch 00017: early stopping\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kj7Bk_poV97Q","colab_type":"text"},"source":["#define a list of test image chunks \n"]},{"cell_type":"code","metadata":{"id":"SpryaCe8Al5f","colab_type":"code","outputId":"001add92-7754-4662-e5d0-5e3f163978f2","executionInfo":{"status":"error","timestamp":1589418298778,"user_tz":240,"elapsed":335,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":246}},"source":["\n","test_names=[]\n","\n","with open(test_set_path,\"r\") as f:\n","  test_image_list=[]\n","  for line in f.readlines():\n","    arr=[]\n","    str_array=line.split(\" \")\n","    arr.append(str_array[0]+\" \"+str_array[1])\n","    arr.append(str_array[2]+\" \"+str_array[3][:-1])\n","    test_image_list.append(arr)\n","    test_names.append(line)\n","\n","test_image_list=np.asarray(test_image_list)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-15447bb250df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstr_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtest_image_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtest_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","metadata":{"id":"hZw0KDjFV_yk","colab_type":"text"},"source":["#read test chunks in batches using the list defined above \n"]},{"cell_type":"code","metadata":{"id":"my-pI2L4smKf","colab_type":"code","colab":{}},"source":["\n","import imageio\n","import numpy as np\n","from keras.utils import to_categorical\n","\n","def read_test_image_batch(image_list, batch_size, channel_list):\n","    while True:\n","        l=len(image_list)\n","        num_batch=l//batch_size\n","        if num_batch*batch_size<l:\n","            num_batch+=1\n","        for i in range(num_batch):\n","            batch_set=image_list[batch_size*i:min(batch_size*(i+1),l),:]\n","            batch_set=[batch_set[bs] for bs in range(len(batch_set))]\n","            X=np.array([np.load(line[0][0:]) for line in batch_set])\n","            labels=np.array([np.load(line[1][0:]) for line in batch_set])\n","            y=to_categorical(labels,num_classes)\n","            X = X[:, :, :, channel_list]\n","            yield tuple((X, y))\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AiB6Qm0oWE4m","colab_type":"text"},"source":["#testing model\n"]},{"cell_type":"code","metadata":{"id":"BW4Mjj1a-mY6","colab_type":"code","outputId":"cf2c5274-b247-479a-e354-0bcdca3ec902","executionInfo":{"status":"error","timestamp":1589418316063,"user_tz":240,"elapsed":399,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":246}},"source":["import argparse\n","from keras.models import Model\n","from keras.layers import Activation,Input\n","from scipy.stats import mode\n","import os\n","\n","\n","class_labels=[]\n","\n","\n","for i in os.listdir(model_path):\n","    if(i==\".ipynb_checkpoints\"):\n","        continue\n","    \n","    key=0\n","    #if(key!=0):\n","    #   continue\n","    \n","    print(model_path+i)\n","    my_model=create_model()\n","    my_model.compile(optimizer,loss=loss_function,metrics=metrics)\n","    my_model.load_weights(model_path+i)\n","    \n","    test_data=read_test_image_batch(test_image_list,batch_size,set_info[key])\n","    probs=my_model.predict(test_data,steps=(test_set_size+1)//batch_size)\n","    print(\"\\nprobs\")\n","    print(probs.shape)\n","    class_labels.append(probs.argmax(axis=-1))\n","\n","hist = np.histogram(class_labels[0])\n","class_labels=np.asarray(class_labels)\n","u,indices=np.unique(class_labels,return_inverse=True)\n","final_labels=u[np.argmax(np.apply_along_axis(np.bincount,0,indices.reshape(class_labels.shape),None,np.max(indices)+1),axis=0)]\n","\n","for i in range(test_set_size):\n","    line=test_names[i]\n","    print(line)\n","    str_array=line.split(\" \")\n","    scene_id=str_array[1][18:40]\n","    out_str=str_array[1][40:-4]+\"_output.npy\"\n","    print(out_str)\n","    np.save('/content/drive/My Drive/new_test_outputs_key_0/'+scene_id+out_str,final_labels[i])\n","    "],"execution_count":0,"outputs":[{"output_type":"error","ename":"NotADirectoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-e64513079025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\".ipynb_checkpoints\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/My Drive/models/one_percent_transfer/model.h5'"]}]},{"cell_type":"code","metadata":{"id":"JqdvLZbJJ5Qi","colab_type":"code","colab":{}},"source":["\"\"\"\n","This script takes a list of scene ids and creates a file that can be used as input for a segnet model\n","@param string chunk_dir: The abspath base directory where each set of chunks for a scene has its own dir named with its sceneID\n","@param list scene_ids: A list of sceneIDs that exist in the chunk_dir. The chunks of these scenes will be used in the file.\n","@param string out_path: The abspath where the resulting file should be saved.\n","@return int lines_written: the total number of lines (corresponding to a data and label chunk path) in the file.\n","file format:\n","/path/to/scene_chunk.npy,/path/to/scene_chunk_label.npy\n","/path/to/scene_chunk.npy,/path/to/scene_chunk_label.npy\n","/path/to/scene_chunk.npy,/path/to/scene_chunk_label.npy\n","...\n","\"\"\"\n","\n","import os\n","\n","def make_segnet_input_file(chunk_dir, scene_ids, out_path):\n","    existing_scenes = [i for i in os.listdir(chunk_dir) if os.path.isdir(os.path.join(chunk_dir, i))]\n","    # filter out ids that don't exist in the given dir\n","    scene_ids = [i for i in scene_ids if i in existing_scenes]\n","    print(scene_ids)\n","\n","    lines_to_write = []\n","\n","    for i in scene_ids:\n","        scene_dir = os.path.join(chunk_dir, i)\n","        for j in os.listdir(scene_dir):\n","            if j[-9:] != \"label.npy\":\n","                data_path = os.path.join(scene_dir, j)\n","                file_split = os.path.splitext(j)\n","                label_path = os.path.join(scene_dir, file_split[0] + \"_label\" + file_split[1])\n","\n","                lines_to_write.append(\"{},{}\\n\".format(data_path, label_path))\n","\n","    with open(out_path, 'w+') as output:\n","        output.writelines(lines_to_write)\n","\n","    return len(lines_to_write)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"az-Vvf86WQ78","colab_type":"text"},"source":["# Simple script to convert space-delimited chunk-path files to csv for easier file loading.\n","## Old file formats are still available in the metadata directory, but .csv equivalents should be used from now on. This script probably shouldn't been needed again.\n"]},{"cell_type":"code","metadata":{"id":"0disMicfWTZc","colab_type":"code","colab":{}},"source":["import csv\n","metadata_path = \"/content/drive/My Drive/Metadata\"\n","image_files = [i for i in os.listdir(metadata_path) if \".txt\" in i]\n","for i in image_files:\n","    file_name, extension = os.path.splitext(i)\n","    file_path = os.path.join(metadata_path, i)\n","    with open(file_path, 'r') as read_file:\n","        lines = [i[:-1].split(\" \") for i in read_file.readlines() if i]\n","    lines = [[f\"{i[0]} {i[1]}\", f\"{i[2]} {i[3]}\"] for i in lines]\n","\n","    with open(os.path.join(metadata_path, file_name + \".csv\"), 'w') as write_file:\n","        writer = csv.writer(write_file)\n","        writer.writerows(lines)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JM5D3eK4uzSU","colab_type":"code","outputId":"788ac7b4-6482-4580-db06-de5e5a9e1f9b","executionInfo":{"status":"error","timestamp":1589302590191,"user_tz":240,"elapsed":730,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":437}},"source":["metadata_file = [i for i in os.listdir(metadata_path) if \".csv\" in i][0]\n","print(metadata_file)\n","test_img_path = os.path.join(metadata_path, metadata_file)\n","\n","with open(test_img_path) as f:\n","    reader = csv.reader(f)\n","    data = next(reader)\n","\n","print(data[0])\n","print(os.path.isfile(data[0]))\n","\n","test_img = next(data_loader.image_segmentation_generator(data[0], data[1], 1, 2, 512, 512, 512, 512,))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train.csv\n","/content/drive/My Drive/uncompressed_stacked_chunks/LC80651102015019LGN00/chunk_13_12.npy\n","True\n"],"name":"stdout"},{"output_type":"error","ename":"NotADirectoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-0f7f13cc9ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_segmentation_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_segmentation/data_utils/data_loader.py\u001b[0m in \u001b[0;36mimage_segmentation_generator\u001b[0;34m(images_path, segs_path, batch_size, n_classes, input_height, input_width, output_height, output_width, do_augment, augmentation_name)\u001b[0m\n\u001b[1;32m    193\u001b[0m                                  augmentation_name=\"aug_all\"):\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mimg_seg_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pairs_from_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_seg_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mzipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_seg_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_segmentation/data_utils/data_loader.py\u001b[0m in \u001b[0;36mget_pairs_from_paths\u001b[0;34m(images_path, segs_path, ignore_non_matching)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0msegmentation_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdir_entry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_entry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_entry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mACCEPTABLE_IMAGE_FORMATS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/My Drive/uncompressed_stacked_chunks/LC80651102015019LGN00/chunk_13_12.npy'"]}]}]}
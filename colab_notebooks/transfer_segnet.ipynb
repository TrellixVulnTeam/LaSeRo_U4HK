{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_segnet.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BZ80yyThVsON","colab_type":"text"},"source":["#Configuration Parameters"]},{"cell_type":"code","metadata":{"id":"AKJ0WYEK39xn","colab_type":"code","outputId":"b2eac5c7-8b1e-4947-bb3f-61764bedf0e0","executionInfo":{"status":"ok","timestamp":1589461893813,"user_tz":240,"elapsed":19876,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":129}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qWRDYCBmLAOq","colab_type":"code","outputId":"06385f95-5b5a-4848-c3a3-4460d6cb11f4","executionInfo":{"status":"ok","timestamp":1589412833285,"user_tz":240,"elapsed":5459,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import sys\n","import os\n","import argparse\n","import csv\n","\n","import imageio\n","import numpy as np\n","\n","from keras.utils import multi_gpu_model, to_categorical\n","from keras.layers import Activation,Input\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n","from tensorflow import convert_to_tensor\n","\n","sys.path.append(\"/content/drive/My Drive/tf-keras-SegNet\")\n","from model import segnet"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"n4k2qGbmHZ47","colab_type":"code","colab":{}},"source":["base_dir = \"/content/drive/My Drive/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"anRxznYgHeAV","colab_type":"code","colab":{}},"source":["def create_session_paths(session_name, overwrite=False, base_dir='/content/drive/My Drive/'):\n","    models_dir = os.path.join(base_dir, \"models\")\n","    session_dir = os.path.join(models_dir, session_name)\n","    # Prevent accidental overwriting of previous sessions\n","    try:\n","        os.mkdir(session_dir)\n","    except FileExistsError:\n","        if not overwrite:\n","            print(\"Set overwrite to True if you wish to continue\")\n","            raise FileExistsError\n","        print(\"overwriting session\")\n","\n","    model = os.path.join(session_dir, \"model.h5\")\n","    history = os.path.join(session_dir, \"history.json\")\n","    training_log = os.path.join(session_dir, \"logs.csv\")\n","    training_config = os.path.join(session_dir, \"config.json\")\n","    classification_report = os.path.join(session_dir, \"classification_report.txt\")\n","    return {\"model\": model,\n","            \"history\": history,\n","            \"logs\": training_log,\n","            \"config\": training_config,\n","            \"classification_report\": classification_report}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oy2LMxNpHslq","colab_type":"code","outputId":"9004fa27-074a-4108-aade-751e7462d65c","executionInfo":{"status":"ok","timestamp":1589412833291,"user_tz":240,"elapsed":4963,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["session_name = \"one_percent_transfer\"\n","session_paths = create_session_paths(session_name, overwrite=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["overwriting session\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VFdNPyi-H98O","colab_type":"code","outputId":"3c04c905-707a-4750-ab19-72489ee5187d","executionInfo":{"status":"ok","timestamp":1589412833292,"user_tz":240,"elapsed":4662,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["for i in session_paths:\n","    print(session_paths[i])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/models/one_percent_transfer/model.h5\n","/content/drive/My Drive/models/one_percent_transfer/history.json\n","/content/drive/My Drive/models/one_percent_transfer/logs.csv\n","/content/drive/My Drive/models/one_percent_transfer/config.json\n","/content/drive/My Drive/models/one_percent_transfer/classification_report.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M9idtsPKSejQ","colab_type":"code","colab":{}},"source":["def get_image_list(metadata_file_path):\n","    with open(metadata_file_path, 'r') as f:\n","        return [i for i in csv.reader(f) if i]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"euVM0pt-w0Xs","colab_type":"code","colab":{}},"source":["training_set_path = '/content/drive/My Drive/Metadata/one_percent_train.csv'\n","val_set_path = '/content/drive/My Drive/Metadata/one_percent_val.csv'\n","test_set_path = '/content/drive/My Drive/Metadata/one_percent_test.csv'\n","model_path = session_paths[\"model\"]\n","\n","n_splits = 1\n","bands = [2, 3, 4] # number of bands\n","\n","num_classes = 2\n","image_shape = (512, 512, len(bands))\n","padding = ((0, 0), (0, 0))\n","batch_size = 5\n","epochs = 50\n","learning_rate = 0.02\n","\n","training_set_list = get_image_list(training_set_path)\n","val_set_list = get_image_list(val_set_path)\n","\n","training_set_size = len(training_set_list)\n","val_set_size = len(val_set_list)\n","test_set_size = len(test_set_list)\n","\n","loss_function = 'categorical_crossentropy'\n","metrics = ['accuracy']\n","callback_metric = \"val_accuracy\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mCwSixkLDTkN","colab_type":"text"},"source":["# Load segnet and vgg model\n"]},{"cell_type":"code","metadata":{"id":"IR10DGtCLo10","colab_type":"code","outputId":"e2656086-aa3a-4a0f-ed7d-c14caec7e5fe","executionInfo":{"status":"ok","timestamp":1589414599329,"user_tz":240,"elapsed":5200,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["segnet_model = segnet(image_shape, num_classes)\n","# vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=(512,512,3), classes=2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Build enceder done..\n","Build decoder done..\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qtQn_aCnaDsB","colab_type":"code","outputId":"490de229-c333-42c6-aaa0-fa69af694012","executionInfo":{"status":"ok","timestamp":1589414599331,"user_tz":240,"elapsed":4945,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(segnet_model.input)\n","print(segnet_model.output)\n","for i, layer in enumerate(segnet_model.layers):\n","    print(i, layer.name)\n","\n","print(segnet_model.summary())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Tensor(\"input_4:0\", shape=(None, 512, 512, 3), dtype=float32)\n","Tensor(\"activation_104/truediv:0\", shape=(None, 262144, 2), dtype=float32)\n","0 input_4\n","1 conv2d_79\n","2 batch_normalization_79\n","3 activation_79\n","4 conv2d_80\n","5 batch_normalization_80\n","6 activation_80\n","7 max_pooling_with_argmax2d_16\n","8 conv2d_81\n","9 batch_normalization_81\n","10 activation_81\n","11 conv2d_82\n","12 batch_normalization_82\n","13 activation_82\n","14 max_pooling_with_argmax2d_17\n","15 conv2d_83\n","16 batch_normalization_83\n","17 activation_83\n","18 conv2d_84\n","19 batch_normalization_84\n","20 activation_84\n","21 conv2d_85\n","22 batch_normalization_85\n","23 activation_85\n","24 max_pooling_with_argmax2d_18\n","25 conv2d_86\n","26 batch_normalization_86\n","27 activation_86\n","28 conv2d_87\n","29 batch_normalization_87\n","30 activation_87\n","31 conv2d_88\n","32 batch_normalization_88\n","33 activation_88\n","34 max_pooling_with_argmax2d_19\n","35 conv2d_89\n","36 batch_normalization_89\n","37 activation_89\n","38 conv2d_90\n","39 batch_normalization_90\n","40 activation_90\n","41 conv2d_91\n","42 batch_normalization_91\n","43 activation_91\n","44 max_pooling_with_argmax2d_20\n","45 max_unpooling2d_16\n","46 conv2d_92\n","47 batch_normalization_92\n","48 activation_92\n","49 conv2d_93\n","50 batch_normalization_93\n","51 activation_93\n","52 conv2d_94\n","53 batch_normalization_94\n","54 activation_94\n","55 max_unpooling2d_17\n","56 conv2d_95\n","57 batch_normalization_95\n","58 activation_95\n","59 conv2d_96\n","60 batch_normalization_96\n","61 activation_96\n","62 conv2d_97\n","63 batch_normalization_97\n","64 activation_97\n","65 max_unpooling2d_18\n","66 conv2d_98\n","67 batch_normalization_98\n","68 activation_98\n","69 conv2d_99\n","70 batch_normalization_99\n","71 activation_99\n","72 conv2d_100\n","73 batch_normalization_100\n","74 activation_100\n","75 max_unpooling2d_19\n","76 conv2d_101\n","77 batch_normalization_101\n","78 activation_101\n","79 conv2d_102\n","80 batch_normalization_102\n","81 activation_102\n","82 max_unpooling2d_20\n","83 conv2d_103\n","84 batch_normalization_103\n","85 activation_103\n","86 conv2d_104\n","87 batch_normalization_104\n","88 reshape_4\n","89 activation_104\n","Model: \"SegNet\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            (None, 512, 512, 3)  0                                            \n","__________________________________________________________________________________________________\n","conv2d_79 (Conv2D)              (None, 512, 512, 64) 1792        input_4[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_79 (BatchNo (None, 512, 512, 64) 256         conv2d_79[0][0]                  \n","__________________________________________________________________________________________________\n","activation_79 (Activation)      (None, 512, 512, 64) 0           batch_normalization_79[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_80 (Conv2D)              (None, 512, 512, 64) 36928       activation_79[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_80 (BatchNo (None, 512, 512, 64) 256         conv2d_80[0][0]                  \n","__________________________________________________________________________________________________\n","activation_80 (Activation)      (None, 512, 512, 64) 0           batch_normalization_80[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling_with_argmax2d_16 (M [(None, 256, 256, 64 0           activation_80[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_81 (Conv2D)              (None, 256, 256, 128 73856       max_pooling_with_argmax2d_16[0][0\n","__________________________________________________________________________________________________\n","batch_normalization_81 (BatchNo (None, 256, 256, 128 512         conv2d_81[0][0]                  \n","__________________________________________________________________________________________________\n","activation_81 (Activation)      (None, 256, 256, 128 0           batch_normalization_81[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_82 (Conv2D)              (None, 256, 256, 128 147584      activation_81[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_82 (BatchNo (None, 256, 256, 128 512         conv2d_82[0][0]                  \n","__________________________________________________________________________________________________\n","activation_82 (Activation)      (None, 256, 256, 128 0           batch_normalization_82[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling_with_argmax2d_17 (M [(None, 128, 128, 12 0           activation_82[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_83 (Conv2D)              (None, 128, 128, 256 295168      max_pooling_with_argmax2d_17[0][0\n","__________________________________________________________________________________________________\n","batch_normalization_83 (BatchNo (None, 128, 128, 256 1024        conv2d_83[0][0]                  \n","__________________________________________________________________________________________________\n","activation_83 (Activation)      (None, 128, 128, 256 0           batch_normalization_83[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_84 (Conv2D)              (None, 128, 128, 256 590080      activation_83[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_84 (BatchNo (None, 128, 128, 256 1024        conv2d_84[0][0]                  \n","__________________________________________________________________________________________________\n","activation_84 (Activation)      (None, 128, 128, 256 0           batch_normalization_84[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_85 (Conv2D)              (None, 128, 128, 256 590080      activation_84[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_85 (BatchNo (None, 128, 128, 256 1024        conv2d_85[0][0]                  \n","__________________________________________________________________________________________________\n","activation_85 (Activation)      (None, 128, 128, 256 0           batch_normalization_85[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling_with_argmax2d_18 (M [(None, 64, 64, 256) 0           activation_85[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_86 (Conv2D)              (None, 64, 64, 512)  1180160     max_pooling_with_argmax2d_18[0][0\n","__________________________________________________________________________________________________\n","batch_normalization_86 (BatchNo (None, 64, 64, 512)  2048        conv2d_86[0][0]                  \n","__________________________________________________________________________________________________\n","activation_86 (Activation)      (None, 64, 64, 512)  0           batch_normalization_86[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_87 (Conv2D)              (None, 64, 64, 512)  2359808     activation_86[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_87 (BatchNo (None, 64, 64, 512)  2048        conv2d_87[0][0]                  \n","__________________________________________________________________________________________________\n","activation_87 (Activation)      (None, 64, 64, 512)  0           batch_normalization_87[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_88 (Conv2D)              (None, 64, 64, 512)  2359808     activation_87[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_88 (BatchNo (None, 64, 64, 512)  2048        conv2d_88[0][0]                  \n","__________________________________________________________________________________________________\n","activation_88 (Activation)      (None, 64, 64, 512)  0           batch_normalization_88[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling_with_argmax2d_19 (M [(None, 32, 32, 512) 0           activation_88[0][0]              \n","__________________________________________________________________________________________________\n","conv2d_89 (Conv2D)              (None, 32, 32, 512)  2359808     max_pooling_with_argmax2d_19[0][0\n","__________________________________________________________________________________________________\n","batch_normalization_89 (BatchNo (None, 32, 32, 512)  2048        conv2d_89[0][0]                  \n","__________________________________________________________________________________________________\n","activation_89 (Activation)      (None, 32, 32, 512)  0           batch_normalization_89[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_90 (Conv2D)              (None, 32, 32, 512)  2359808     activation_89[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_90 (BatchNo (None, 32, 32, 512)  2048        conv2d_90[0][0]                  \n","__________________________________________________________________________________________________\n","activation_90 (Activation)      (None, 32, 32, 512)  0           batch_normalization_90[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_91 (Conv2D)              (None, 32, 32, 512)  2359808     activation_90[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_91 (BatchNo (None, 32, 32, 512)  2048        conv2d_91[0][0]                  \n","__________________________________________________________________________________________________\n","activation_91 (Activation)      (None, 32, 32, 512)  0           batch_normalization_91[0][0]     \n","__________________________________________________________________________________________________\n","max_pooling_with_argmax2d_20 (M [(None, 16, 16, 512) 0           activation_91[0][0]              \n","__________________________________________________________________________________________________\n","max_unpooling2d_16 (MaxUnpoolin (None, 32, 32, 512)  0           max_pooling_with_argmax2d_20[0][0\n","                                                                 max_pooling_with_argmax2d_20[0][1\n","__________________________________________________________________________________________________\n","conv2d_92 (Conv2D)              (None, 32, 32, 512)  2359808     max_unpooling2d_16[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_92 (BatchNo (None, 32, 32, 512)  2048        conv2d_92[0][0]                  \n","__________________________________________________________________________________________________\n","activation_92 (Activation)      (None, 32, 32, 512)  0           batch_normalization_92[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_93 (Conv2D)              (None, 32, 32, 512)  2359808     activation_92[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_93 (BatchNo (None, 32, 32, 512)  2048        conv2d_93[0][0]                  \n","__________________________________________________________________________________________________\n","activation_93 (Activation)      (None, 32, 32, 512)  0           batch_normalization_93[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_94 (Conv2D)              (None, 32, 32, 512)  2359808     activation_93[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_94 (BatchNo (None, 32, 32, 512)  2048        conv2d_94[0][0]                  \n","__________________________________________________________________________________________________\n","activation_94 (Activation)      (None, 32, 32, 512)  0           batch_normalization_94[0][0]     \n","__________________________________________________________________________________________________\n","max_unpooling2d_17 (MaxUnpoolin (None, 64, 64, 512)  0           activation_94[0][0]              \n","                                                                 max_pooling_with_argmax2d_19[0][1\n","__________________________________________________________________________________________________\n","conv2d_95 (Conv2D)              (None, 64, 64, 512)  2359808     max_unpooling2d_17[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_95 (BatchNo (None, 64, 64, 512)  2048        conv2d_95[0][0]                  \n","__________________________________________________________________________________________________\n","activation_95 (Activation)      (None, 64, 64, 512)  0           batch_normalization_95[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_96 (Conv2D)              (None, 64, 64, 512)  2359808     activation_95[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_96 (BatchNo (None, 64, 64, 512)  2048        conv2d_96[0][0]                  \n","__________________________________________________________________________________________________\n","activation_96 (Activation)      (None, 64, 64, 512)  0           batch_normalization_96[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_97 (Conv2D)              (None, 64, 64, 256)  1179904     activation_96[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_97 (BatchNo (None, 64, 64, 256)  1024        conv2d_97[0][0]                  \n","__________________________________________________________________________________________________\n","activation_97 (Activation)      (None, 64, 64, 256)  0           batch_normalization_97[0][0]     \n","__________________________________________________________________________________________________\n","max_unpooling2d_18 (MaxUnpoolin (None, 128, 128, 256 0           activation_97[0][0]              \n","                                                                 max_pooling_with_argmax2d_18[0][1\n","__________________________________________________________________________________________________\n","conv2d_98 (Conv2D)              (None, 128, 128, 256 590080      max_unpooling2d_18[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_98 (BatchNo (None, 128, 128, 256 1024        conv2d_98[0][0]                  \n","__________________________________________________________________________________________________\n","activation_98 (Activation)      (None, 128, 128, 256 0           batch_normalization_98[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_99 (Conv2D)              (None, 128, 128, 256 590080      activation_98[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_99 (BatchNo (None, 128, 128, 256 1024        conv2d_99[0][0]                  \n","__________________________________________________________________________________________________\n","activation_99 (Activation)      (None, 128, 128, 256 0           batch_normalization_99[0][0]     \n","__________________________________________________________________________________________________\n","conv2d_100 (Conv2D)             (None, 128, 128, 128 295040      activation_99[0][0]              \n","__________________________________________________________________________________________________\n","batch_normalization_100 (BatchN (None, 128, 128, 128 512         conv2d_100[0][0]                 \n","__________________________________________________________________________________________________\n","activation_100 (Activation)     (None, 128, 128, 128 0           batch_normalization_100[0][0]    \n","__________________________________________________________________________________________________\n","max_unpooling2d_19 (MaxUnpoolin (None, 256, 256, 128 0           activation_100[0][0]             \n","                                                                 max_pooling_with_argmax2d_17[0][1\n","__________________________________________________________________________________________________\n","conv2d_101 (Conv2D)             (None, 256, 256, 128 147584      max_unpooling2d_19[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_101 (BatchN (None, 256, 256, 128 512         conv2d_101[0][0]                 \n","__________________________________________________________________________________________________\n","activation_101 (Activation)     (None, 256, 256, 128 0           batch_normalization_101[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_102 (Conv2D)             (None, 256, 256, 64) 73792       activation_101[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_102 (BatchN (None, 256, 256, 64) 256         conv2d_102[0][0]                 \n","__________________________________________________________________________________________________\n","activation_102 (Activation)     (None, 256, 256, 64) 0           batch_normalization_102[0][0]    \n","__________________________________________________________________________________________________\n","max_unpooling2d_20 (MaxUnpoolin (None, 512, 512, 64) 0           activation_102[0][0]             \n","                                                                 max_pooling_with_argmax2d_16[0][1\n","__________________________________________________________________________________________________\n","conv2d_103 (Conv2D)             (None, 512, 512, 64) 36928       max_unpooling2d_20[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_103 (BatchN (None, 512, 512, 64) 256         conv2d_103[0][0]                 \n","__________________________________________________________________________________________________\n","activation_103 (Activation)     (None, 512, 512, 64) 0           batch_normalization_103[0][0]    \n","__________________________________________________________________________________________________\n","conv2d_104 (Conv2D)             (None, 512, 512, 2)  130         activation_103[0][0]             \n","__________________________________________________________________________________________________\n","batch_normalization_104 (BatchN (None, 512, 512, 2)  8           conv2d_104[0][0]                 \n","__________________________________________________________________________________________________\n","reshape_4 (Reshape)             (None, 262144, 2)    0           batch_normalization_104[0][0]    \n","__________________________________________________________________________________________________\n","activation_104 (Activation)     (None, 262144, 2)    0           reshape_4[0][0]                  \n","==================================================================================================\n","Total params: 29,459,018\n","Trainable params: 29,443,142\n","Non-trainable params: 15,876\n","__________________________________________________________________________________________________\n","None\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jS01ZdNVDXjJ","colab_type":"text"},"source":["# Transfer weights of matching layers from image-net trained vgg16 to segnet"]},{"cell_type":"markdown","metadata":{"id":"h2NZIihQWBxg","colab_type":"text"},"source":["#Training model \n"]},{"cell_type":"code","metadata":{"id":"55indsfD1s5J","colab_type":"code","colab":{}},"source":["def data_gen(metadata_file_path, bands, batch_size):\n","    image_list = np.asarray(get_image_list(metadata_file_path))\n","    np.random.seed(1)\n","    np.random.shuffle(image_list)\n","\n","    band_normalization_map = []\n","    counter = 0\n","\n","    total_steps = image_list.shape[0] // batch_size\n","    while True:\n","        step_start = counter * batch_size\n","        step_end = step_start + batch_size\n","        images = []\n","        masks = []\n","        for j in range(step_start, step_end):\n","            images.append(np.load(image_list[j, 0])[:,:,bands])\n","            masks.append(np.load(image_list[j, 1]))\n","\n","        y = to_categorical(np.array(masks))\n","        yield np.array(images), y.reshape((batch_size, y.shape[1] * y.shape[2], y.shape[3]))\n","\n","        counter +=1\n","\n","        if counter >= total_steps:\n","            counter = 0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SMKEnOm3E8f7","colab_type":"code","outputId":"fff21702-1127-4fbc-b417-7792e7813f7d","executionInfo":{"status":"ok","timestamp":1589418175121,"user_tz":240,"elapsed":3576907,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["args = {\"save\": \"model_allBands\", \"resume\":False, \"load\": \"model_allBands\", \"opt\": Adam(learning_rate=learning_rate)}\n","\n","train_data = data_gen(training_set_path, bands, batch_size)\n","val_data = data_gen(val_set_path, bands, batch_size)\n","\n","segnet_model.compile(optimizer=args['opt'], loss=loss_function, metrics=metrics)\n","\n","checkpoint = ModelCheckpoint(session_paths[\"model\"],\n","                             monitor=callback_metric,\n","                             verbose=1,\n","                             save_best_only=True,\n","                             mode='max')\n","\n","reduce_lr = ReduceLROnPlateau(monitor=callback_metric,\n","                              factor=0.5,\n","                              patience=3,\n","                              verbose=1,\n","                              mode='max',\n","                              min_lr=0.0001)\n","\n","csv_logger = CSVLogger(session_paths[\"logs\"])\n","\n","early_stopper = EarlyStopping(monitor=callback_metric,\n","                              patience=9,\n","                              verbose=1,\n","                              mode='max')\n","\n","callbacks_list = [checkpoint, reduce_lr, csv_logger, early_stopper]\n","\n","try:\n","    model = multi_gpu_model(model)\n","except:\n","    print(\"single GPU in use\")\n","\n","hist = segnet_model.fit(train_data,\n","                        steps_per_epoch=training_set_size // batch_size,\n","                        epochs=epochs,\n","                        validation_data=val_data,\n","                        validation_steps=val_set_size // batch_size,\n","                        verbose=1,\n","                        callbacks=callbacks_list)\n","\n","val_loss = hist.history[\"val_loss\"]"],"execution_count":0,"outputs":[{"output_type":"stream","text":["single GPU in use\n","Epoch 1/50\n","154/154 [==============================] - 227s 1s/step - loss: 0.3077 - accuracy: 0.9246 - val_loss: 15.6793 - val_accuracy: 0.0801\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.08006, saving model to /content/drive/My Drive/models/one_percent_transfer/model.h5\n","Epoch 2/50\n","154/154 [==============================] - 194s 1s/step - loss: 0.1776 - accuracy: 0.9354 - val_loss: 0.1682 - val_accuracy: 0.8923\n","\n","Epoch 00002: val_accuracy improved from 0.08006 to 0.89227, saving model to /content/drive/My Drive/models/one_percent_transfer/model.h5\n","Epoch 3/50\n","154/154 [==============================] - 194s 1s/step - loss: 0.1536 - accuracy: 0.9406 - val_loss: 0.1418 - val_accuracy: 0.9200\n","\n","Epoch 00003: val_accuracy improved from 0.89227 to 0.92003, saving model to /content/drive/My Drive/models/one_percent_transfer/model.h5\n","Epoch 4/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.1610 - accuracy: 0.9373 - val_loss: 0.1716 - val_accuracy: 0.9184\n","\n","Epoch 00004: val_accuracy did not improve from 0.92003\n","Epoch 5/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.1611 - accuracy: 0.9408 - val_loss: 4.9007 - val_accuracy: 0.2746\n","\n","Epoch 00005: val_accuracy did not improve from 0.92003\n","Epoch 6/50\n","154/154 [==============================] - 194s 1s/step - loss: 0.1643 - accuracy: 0.9327 - val_loss: 6.4208 - val_accuracy: 0.1882\n","\n","Epoch 00006: val_accuracy did not improve from 0.92003\n","\n","Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.009999999776482582.\n","Epoch 7/50\n","154/154 [==============================] - 194s 1s/step - loss: 0.1401 - accuracy: 0.9442 - val_loss: 0.0756 - val_accuracy: 0.9431\n","\n","Epoch 00007: val_accuracy improved from 0.92003 to 0.94308, saving model to /content/drive/My Drive/models/one_percent_transfer/model.h5\n","Epoch 8/50\n","154/154 [==============================] - 194s 1s/step - loss: 0.1289 - accuracy: 0.9486 - val_loss: 0.0745 - val_accuracy: 0.9375\n","\n","Epoch 00008: val_accuracy did not improve from 0.94308\n","Epoch 9/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.1268 - accuracy: 0.9494 - val_loss: 0.0754 - val_accuracy: 0.9491\n","\n","Epoch 00009: val_accuracy improved from 0.94308 to 0.94908, saving model to /content/drive/My Drive/models/one_percent_transfer/model.h5\n","Epoch 10/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.1223 - accuracy: 0.9514 - val_loss: 0.2146 - val_accuracy: 0.9146\n","\n","Epoch 00010: val_accuracy did not improve from 0.94908\n","Epoch 11/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.1198 - accuracy: 0.9528 - val_loss: 0.1261 - val_accuracy: 0.9398\n","\n","Epoch 00011: val_accuracy did not improve from 0.94908\n","Epoch 12/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.1124 - accuracy: 0.9562 - val_loss: 0.2477 - val_accuracy: 0.9172\n","\n","Epoch 00012: val_accuracy did not improve from 0.94908\n","\n","Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n","Epoch 13/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.1012 - accuracy: 0.9621 - val_loss: 0.1216 - val_accuracy: 0.9453\n","\n","Epoch 00013: val_accuracy did not improve from 0.94908\n","Epoch 14/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.0966 - accuracy: 0.9648 - val_loss: 0.1827 - val_accuracy: 0.9278\n","\n","Epoch 00014: val_accuracy did not improve from 0.94908\n","Epoch 15/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.0939 - accuracy: 0.9665 - val_loss: 0.1433 - val_accuracy: 0.9328\n","\n","Epoch 00015: val_accuracy did not improve from 0.94908\n","\n","Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0024999999441206455.\n","Epoch 16/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.0851 - accuracy: 0.9709 - val_loss: 0.2019 - val_accuracy: 0.9110\n","\n","Epoch 00016: val_accuracy did not improve from 0.94908\n","Epoch 17/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.0829 - accuracy: 0.9717 - val_loss: 0.2378 - val_accuracy: 0.8833\n","\n","Epoch 00017: val_accuracy did not improve from 0.94908\n","Epoch 18/50\n","154/154 [==============================] - 193s 1s/step - loss: 0.0814 - accuracy: 0.9721 - val_loss: 0.2854 - val_accuracy: 0.8576\n","\n","Epoch 00018: val_accuracy did not improve from 0.94908\n","\n","Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0012499999720603228.\n","Epoch 00018: early stopping\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kj7Bk_poV97Q","colab_type":"text"},"source":["#define a list of test image chunks \n"]},{"cell_type":"code","metadata":{"id":"SpryaCe8Al5f","colab_type":"code","outputId":"001add92-7754-4662-e5d0-5e3f163978f2","executionInfo":{"status":"error","timestamp":1589418298778,"user_tz":240,"elapsed":335,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":246}},"source":["\n","test_names=[]\n","\n","with open(test_set_path,\"r\") as f:\n","  test_image_list=[]\n","  for line in f.readlines():\n","    arr=[]\n","    str_array=line.split(\" \")\n","    arr.append(str_array[0]+\" \"+str_array[1])\n","    arr.append(str_array[2]+\" \"+str_array[3][:-1])\n","    test_image_list.append(arr)\n","    test_names.append(line)\n","\n","test_image_list=np.asarray(test_image_list)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-15447bb250df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mstr_array\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mtest_image_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtest_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","metadata":{"id":"hZw0KDjFV_yk","colab_type":"text"},"source":["#read test chunks in batches using the list defined above \n"]},{"cell_type":"code","metadata":{"id":"my-pI2L4smKf","colab_type":"code","colab":{}},"source":["\n","import imageio\n","import numpy as np\n","from keras.utils import to_categorical\n","\n","def read_test_image_batch(image_list, batch_size, channel_list):\n","    while True:\n","        l=len(image_list)\n","        num_batch=l//batch_size\n","        if num_batch*batch_size<l:\n","            num_batch+=1\n","        for i in range(num_batch):\n","            batch_set=image_list[batch_size*i:min(batch_size*(i+1),l),:]\n","            batch_set=[batch_set[bs] for bs in range(len(batch_set))]\n","            X=np.array([np.load(line[0][0:]) for line in batch_set])\n","            labels=np.array([np.load(line[1][0:]) for line in batch_set])\n","            y=to_categorical(labels,num_classes)\n","            X = X[:, :, :, channel_list]\n","            yield tuple((X, y))\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AiB6Qm0oWE4m","colab_type":"text"},"source":["#testing model\n"]},{"cell_type":"code","metadata":{"id":"BW4Mjj1a-mY6","colab_type":"code","outputId":"cf2c5274-b247-479a-e354-0bcdca3ec902","executionInfo":{"status":"error","timestamp":1589418316063,"user_tz":240,"elapsed":399,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":246}},"source":["import argparse\n","from keras.models import Model\n","from keras.layers import Activation,Input\n","from scipy.stats import mode\n","import os\n","\n","\n","class_labels=[]\n","\n","\n","for i in os.listdir(model_path):\n","    if(i==\".ipynb_checkpoints\"):\n","        continue\n","    \n","    key=0\n","    #if(key!=0):\n","    #   continue\n","    \n","    print(model_path+i)\n","    my_model=create_model()\n","    my_model.compile(optimizer,loss=loss_function,metrics=metrics)\n","    my_model.load_weights(model_path+i)\n","    \n","    test_data=read_test_image_batch(test_image_list,batch_size,set_info[key])\n","    probs=my_model.predict(test_data,steps=(test_set_size+1)//batch_size)\n","    print(\"\\nprobs\")\n","    print(probs.shape)\n","    class_labels.append(probs.argmax(axis=-1))\n","\n","hist = np.histogram(class_labels[0])\n","class_labels=np.asarray(class_labels)\n","u,indices=np.unique(class_labels,return_inverse=True)\n","final_labels=u[np.argmax(np.apply_along_axis(np.bincount,0,indices.reshape(class_labels.shape),None,np.max(indices)+1),axis=0)]\n","\n","for i in range(test_set_size):\n","    line=test_names[i]\n","    print(line)\n","    str_array=line.split(\" \")\n","    scene_id=str_array[1][18:40]\n","    out_str=str_array[1][40:-4]+\"_output.npy\"\n","    print(out_str)\n","    np.save('/content/drive/My Drive/new_test_outputs_key_0/'+scene_id+out_str,final_labels[i])\n","    "],"execution_count":0,"outputs":[{"output_type":"error","ename":"NotADirectoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-e64513079025>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\".ipynb_checkpoints\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/My Drive/models/one_percent_transfer/model.h5'"]}]},{"cell_type":"code","metadata":{"id":"JqdvLZbJJ5Qi","colab_type":"code","colab":{}},"source":["\"\"\"\n","This script takes a list of scene ids and creates a file that can be used as input for a segnet model\n","@param string chunk_dir: The abspath base directory where each set of chunks for a scene has its own dir named with its sceneID\n","@param list scene_ids: A list of sceneIDs that exist in the chunk_dir. The chunks of these scenes will be used in the file.\n","@param string out_path: The abspath where the resulting file should be saved.\n","@return int lines_written: the total number of lines (corresponding to a data and label chunk path) in the file.\n","file format:\n","/path/to/scene_chunk.npy,/path/to/scene_chunk_label.npy\n","/path/to/scene_chunk.npy,/path/to/scene_chunk_label.npy\n","/path/to/scene_chunk.npy,/path/to/scene_chunk_label.npy\n","...\n","\"\"\"\n","\n","import os\n","\n","def make_segnet_input_file(chunk_dir, scene_ids, out_path):\n","    existing_scenes = [i for i in os.listdir(chunk_dir) if os.path.isdir(os.path.join(chunk_dir, i))]\n","    # filter out ids that don't exist in the given dir\n","    scene_ids = [i for i in scene_ids if i in existing_scenes]\n","    print(scene_ids)\n","\n","    lines_to_write = []\n","\n","    for i in scene_ids:\n","        scene_dir = os.path.join(chunk_dir, i)\n","        for j in os.listdir(scene_dir):\n","            if j[-9:] != \"label.npy\":\n","                data_path = os.path.join(scene_dir, j)\n","                file_split = os.path.splitext(j)\n","                label_path = os.path.join(scene_dir, file_split[0] + \"_label\" + file_split[1])\n","\n","                lines_to_write.append(\"{},{}\\n\".format(data_path, label_path))\n","\n","    with open(out_path, 'w+') as output:\n","        output.writelines(lines_to_write)\n","\n","    return len(lines_to_write)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"az-Vvf86WQ78","colab_type":"text"},"source":["# Simple script to convert space-delimited chunk-path files to csv for easier file loading.\n","## Old file formats are still available in the metadata directory, but .csv equivalents should be used from now on. This script probably shouldn't been needed again.\n"]},{"cell_type":"code","metadata":{"id":"0disMicfWTZc","colab_type":"code","colab":{}},"source":["import csv\n","metadata_path = \"/content/drive/My Drive/Metadata\"\n","image_files = [i for i in os.listdir(metadata_path) if \".txt\" in i]\n","for i in image_files:\n","    file_name, extension = os.path.splitext(i)\n","    file_path = os.path.join(metadata_path, i)\n","    with open(file_path, 'r') as read_file:\n","        lines = [i[:-1].split(\" \") for i in read_file.readlines() if i]\n","    lines = [[f\"{i[0]} {i[1]}\", f\"{i[2]} {i[3]}\"] for i in lines]\n","\n","    with open(os.path.join(metadata_path, file_name + \".csv\"), 'w') as write_file:\n","        writer = csv.writer(write_file)\n","        writer.writerows(lines)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JM5D3eK4uzSU","colab_type":"code","outputId":"788ac7b4-6482-4580-db06-de5e5a9e1f9b","executionInfo":{"status":"error","timestamp":1589302590191,"user_tz":240,"elapsed":730,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":437}},"source":["metadata_file = [i for i in os.listdir(metadata_path) if \".csv\" in i][0]\n","print(metadata_file)\n","test_img_path = os.path.join(metadata_path, metadata_file)\n","\n","with open(test_img_path) as f:\n","    reader = csv.reader(f)\n","    data = next(reader)\n","\n","print(data[0])\n","print(os.path.isfile(data[0]))\n","\n","test_img = next(data_loader.image_segmentation_generator(data[0], data[1], 1, 2, 512, 512, 512, 512,))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train.csv\n","/content/drive/My Drive/uncompressed_stacked_chunks/LC80651102015019LGN00/chunk_13_12.npy\n","True\n"],"name":"stdout"},{"output_type":"error","ename":"NotADirectoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-0f7f13cc9ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_segmentation_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_segmentation/data_utils/data_loader.py\u001b[0m in \u001b[0;36mimage_segmentation_generator\u001b[0;34m(images_path, segs_path, batch_size, n_classes, input_height, input_width, output_height, output_width, do_augment, augmentation_name)\u001b[0m\n\u001b[1;32m    193\u001b[0m                                  augmentation_name=\"aug_all\"):\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mimg_seg_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pairs_from_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_seg_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mzipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_seg_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_segmentation/data_utils/data_loader.py\u001b[0m in \u001b[0;36mget_pairs_from_paths\u001b[0;34m(images_path, segs_path, ignore_non_matching)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0msegmentation_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdir_entry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_entry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_entry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mACCEPTABLE_IMAGE_FORMATS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/My Drive/uncompressed_stacked_chunks/LC80651102015019LGN00/chunk_13_12.npy'"]}]}]}
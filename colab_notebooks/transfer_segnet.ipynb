{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_segnet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BZ80yyThVsON","colab_type":"text"},"source":["#Configuration Parameters"]},{"cell_type":"code","metadata":{"id":"AKJ0WYEK39xn","colab_type":"code","outputId":"fa47a9ce-4cd5-4a55-cbbf-ccb1712b3f41","executionInfo":{"status":"ok","timestamp":1589904728294,"user_tz":240,"elapsed":889,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VjH6TLOZq1d4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":311},"outputId":"f0e5b018-c311-4486-d444-f7a5c31aa049","executionInfo":{"status":"ok","timestamp":1589904733147,"user_tz":240,"elapsed":2732,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}}},"source":["!nvidia-smi"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Tue May 19 16:12:12 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   73C    P0    77W / 149W |  10868MiB / 11441MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qWRDYCBmLAOq","colab_type":"code","colab":{}},"source":["import sys\n","import os\n","import argparse\n","import csv\n","\n","import imageio\n","import numpy as np\n","\n","from keras.utils import multi_gpu_model, to_categorical\n","from keras.layers import Activation,Input\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n","from tensorflow import convert_to_tensor\n","\n","sys.path.append(\"/content/drive/My Drive/tf-keras-SegNet\")\n","from model import segnet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"n4k2qGbmHZ47","colab_type":"code","colab":{}},"source":["base_dir = \"/content/drive/My Drive/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"anRxznYgHeAV","colab_type":"code","colab":{}},"source":["def create_session_paths(session_name, overwrite=False, base_dir='/content/drive/My Drive/'):\n","    models_dir = os.path.join(base_dir, \"models\")\n","    session_dir = os.path.join(models_dir, session_name)\n","    # Prevent accidental overwriting of previous sessions\n","    try:\n","        os.mkdir(session_dir)\n","    except FileExistsError:\n","        if not overwrite:\n","            print(\"Set overwrite to True if you wish to continue\")\n","            raise FileExistsError\n","        print(\"overwriting session\")\n","\n","    model = os.path.join(session_dir, f\"{session_name}.h5\")\n","    history = os.path.join(session_dir, \"history.json\")\n","    training_log = os.path.join(session_dir, \"logs.csv\")\n","    training_config = os.path.join(session_dir, \"config.json\")\n","    classification_report = os.path.join(session_dir, \"classification_report.txt\")\n","    return {\"model\": model,\n","            \"history\": history,\n","            \"logs\": training_log,\n","            \"config\": training_config,\n","            \"classification_report\": classification_report}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oy2LMxNpHslq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"6e21be2a-2772-45a0-9465-aae5851d4e8c","executionInfo":{"status":"ok","timestamp":1589904737204,"user_tz":240,"elapsed":863,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}}},"source":["session_name = \"one_percent_transfer_rgb_lr_0.001\"\n","session_paths = create_session_paths(session_name, overwrite=True)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["overwriting session\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VFdNPyi-H98O","colab_type":"code","outputId":"13618d55-6f82-4041-af9b-5f47411f69d6","executionInfo":{"status":"ok","timestamp":1589904737204,"user_tz":240,"elapsed":650,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["for i in session_paths:\n","    print(session_paths[i])"],"execution_count":20,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/models/one_percent_transfer_rgb_lr_0.001/one_percent_transfer_rgb_lr_0.001.h5\n","/content/drive/My Drive/models/one_percent_transfer_rgb_lr_0.001/history.json\n","/content/drive/My Drive/models/one_percent_transfer_rgb_lr_0.001/logs.csv\n","/content/drive/My Drive/models/one_percent_transfer_rgb_lr_0.001/config.json\n","/content/drive/My Drive/models/one_percent_transfer_rgb_lr_0.001/classification_report.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M9idtsPKSejQ","colab_type":"code","colab":{}},"source":["def get_image_list(metadata_file_path):\n","    with open(metadata_file_path, 'r') as f:\n","        return [i for i in csv.reader(f) if i]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"euVM0pt-w0Xs","colab_type":"code","colab":{}},"source":["training_set_path = '/content/drive/My Drive/Metadata/one_percent_train.csv'\n","val_set_path = '/content/drive/My Drive/Metadata/one_percent_val.csv'\n","test_set_path = '/content/drive/My Drive/Metadata/one_percent_test.csv'\n","model_path = session_paths[\"model\"]\n","\n","n_splits = 1\n","bands = [1, 2, 3] # number of bands\n","\n","num_classes = 2\n","image_shape = (512, 512, len(bands))\n","padding = ((0, 0), (0, 0))\n","batch_size = 4\n","epochs = 50\n","learning_rate = 0.001\n","\n","training_set_list = get_image_list(training_set_path)\n","val_set_list = get_image_list(val_set_path)\n","\n","training_set_size = len(training_set_list)\n","val_set_size = len(val_set_list)\n","\n","loss_function = 'categorical_crossentropy'\n","metrics = ['accuracy']\n","callback_metric = \"val_accuracy\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mCwSixkLDTkN","colab_type":"text"},"source":["# Load segnet and vgg model\n"]},{"cell_type":"code","metadata":{"id":"IR10DGtCLo10","colab_type":"code","outputId":"31fa8eb8-6249-4704-fdb4-8fca08fd87cb","executionInfo":{"status":"ok","timestamp":1589905023741,"user_tz":240,"elapsed":2776,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["segnet_model = segnet(image_shape, num_classes)\n","vgg_model = VGG16(include_top=False, weights='imagenet', input_shape=image_shape, classes=num_classes)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Build enceder done..\n","Build decoder done..\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qtQn_aCnaDsB","colab_type":"code","outputId":"9698cb5f-f209-4392-fbab-182cf28c8018","executionInfo":{"status":"ok","timestamp":1589905023741,"user_tz":240,"elapsed":2637,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["seg_layer_names = [i for i in segnet_model.layers if \"conv\" in i.name]\n","vgg_layer_names = [i for i in vgg_model.layers if \"conv\" in i.name]\n","\n","transferable_layer_names = {}\n","for i in range(len(vgg_layer_names)):\n","    transferable_layer_names[seg_layer_names[i].name] = vgg_layer_names[i]\n","\n","layer_count = 0\n","for i in segnet_model.layers:\n","    try:\n","        i.set_weights(transferable_layer_names[i.name].get_weights())\n","        layer_count += 1\n","    except KeyError:\n","        pass\n","\n","print(layer_count)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["13\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jS01ZdNVDXjJ","colab_type":"text"},"source":["# Transfer weights of matching layers from image-net trained vgg16 to segnet"]},{"cell_type":"markdown","metadata":{"id":"h2NZIihQWBxg","colab_type":"text"},"source":["#Training model \n"]},{"cell_type":"code","metadata":{"id":"55indsfD1s5J","colab_type":"code","colab":{}},"source":["def data_gen(metadata_file_path, bands, batch_size):\n","    image_list = np.asarray(get_image_list(metadata_file_path))\n","    np.random.seed(1)\n","    np.random.shuffle(image_list)\n","\n","    band_normalization_map = []\n","    counter = 0\n","\n","    total_steps = image_list.shape[0] // batch_size\n","    while True:\n","        step_start = counter * batch_size\n","        step_end = step_start + batch_size\n","        images = []\n","        masks = []\n","        for j in range(step_start, step_end):\n","            images.append(np.load(image_list[j, 0])[:,:,bands])\n","            masks.append(np.load(image_list[j, 1]))\n","\n","        y = to_categorical(np.array(masks))\n","        yield np.array(images) / 65535, y.reshape((batch_size, y.shape[1] * y.shape[2], y.shape[3]))\n","\n","        counter +=1\n","\n","        if counter >= total_steps:\n","            counter = 0\n","            np.random.shuffle(image_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SMKEnOm3E8f7","colab_type":"code","outputId":"c1a8ef02-a34d-47eb-f863-f62515fa51fb","executionInfo":{"status":"ok","timestamp":1589914453144,"user_tz":240,"elapsed":9431505,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train_data = data_gen(training_set_path, bands, batch_size)\n","val_data = data_gen(val_set_path, bands, batch_size)\n","\n","segnet_model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss_function, metrics=metrics)\n","\n","save_model_path, model_file = os.path.split(session_paths[\"model\"])\n","save_model_file, model_ext = os.path.splitext(model_file)\n","save_model_prefix = os.path.join(save_model_path, save_model_file)\n","\n","best_checkpoint = ModelCheckpoint(session_paths[\"model\"],\n","                             monitor=callback_metric,\n","                             verbose=1,\n","                             save_best_only=True,\n","                             mode='max')\n","\n","checkpoint = ModelCheckpoint(save_model_prefix + \"_epoch{epoch:02d}.h5\",\n","                             period=5,\n","                             save_weights_only=False,\n","                             save_best_only=False)\n","\n","reduce_lr = ReduceLROnPlateau(monitor=callback_metric,\n","                              factor=0.5,\n","                              patience=3,\n","                              verbose=1,\n","                              mode='max',\n","                              min_lr=0.0001)\n","\n","csv_logger = CSVLogger(session_paths[\"logs\"])\n","\n","early_stopper = EarlyStopping(monitor=callback_metric,\n","                              patience=9,\n","                              verbose=1,\n","                              mode='max')\n","\n","callbacks_list = [checkpoint, best_checkpoint, reduce_lr, csv_logger, early_stopper]\n","\n","try:\n","    model = multi_gpu_model(model)\n","except:\n","    print(\"single GPU in use\")\n","\n","hist = segnet_model.fit(train_data,\n","                        steps_per_epoch=training_set_size // batch_size,\n","                        epochs=epochs,\n","                        validation_data=val_data,\n","                        validation_steps=val_set_size // batch_size,\n","                        verbose=1,\n","                        callbacks=callbacks_list)\n","\n","val_loss = hist.history[\"val_loss\"]"],"execution_count":36,"outputs":[{"output_type":"stream","text":["single GPU in use\n","Epoch 1/50\n","192/192 [==============================] - 1000s 5s/step - loss: 0.6079 - accuracy: 0.8018 - val_loss: 8.0231 - val_accuracy: 0.4947\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.49472, saving model to /content/drive/My Drive/models/one_percent_transfer_rgb_lr_0.001/one_percent_transfer_rgb_lr_0.001.h5\n","Epoch 2/50\n","192/192 [==============================] - 598s 3s/step - loss: 0.4725 - accuracy: 0.8964 - val_loss: 0.5491 - val_accuracy: 0.9184\n","\n","Epoch 00002: val_accuracy improved from 0.49472 to 0.91840, saving model to /content/drive/My Drive/models/one_percent_transfer_rgb_lr_0.001/one_percent_transfer_rgb_lr_0.001.h5\n","Epoch 3/50\n","192/192 [==============================] - 598s 3s/step - loss: 0.3794 - accuracy: 0.9176 - val_loss: 0.4780 - val_accuracy: 0.9227\n","\n","Epoch 00003: val_accuracy improved from 0.91840 to 0.92269, saving model to /content/drive/My Drive/models/one_percent_transfer_rgb_lr_0.001/one_percent_transfer_rgb_lr_0.001.h5\n","Epoch 4/50\n","192/192 [==============================] - 599s 3s/step - loss: 0.3165 - accuracy: 0.9318 - val_loss: 0.5216 - val_accuracy: 0.8920\n","\n","Epoch 00004: val_accuracy did not improve from 0.92269\n","Epoch 5/50\n","192/192 [==============================] - 598s 3s/step - loss: 0.2758 - accuracy: 0.9377 - val_loss: 0.3857 - val_accuracy: 0.9279\n","\n","Epoch 00005: val_accuracy improved from 0.92269 to 0.92789, saving model to /content/drive/My Drive/models/one_percent_transfer_rgb_lr_0.001/one_percent_transfer_rgb_lr_0.001.h5\n","Epoch 6/50\n","192/192 [==============================] - 598s 3s/step - loss: 0.2414 - accuracy: 0.9427 - val_loss: 0.2592 - val_accuracy: 0.9466\n","\n","Epoch 00006: val_accuracy improved from 0.92789 to 0.94656, saving model to /content/drive/My Drive/models/one_percent_transfer_rgb_lr_0.001/one_percent_transfer_rgb_lr_0.001.h5\n","Epoch 7/50\n","192/192 [==============================] - 598s 3s/step - loss: 0.2107 - accuracy: 0.9481 - val_loss: 0.1657 - val_accuracy: 0.9391\n","\n","Epoch 00007: val_accuracy did not improve from 0.94656\n","Epoch 8/50\n","192/192 [==============================] - 598s 3s/step - loss: 0.1893 - accuracy: 0.9522 - val_loss: 0.1682 - val_accuracy: 0.9269\n","\n","Epoch 00008: val_accuracy did not improve from 0.94656\n","Epoch 9/50\n","192/192 [==============================] - 597s 3s/step - loss: 0.1848 - accuracy: 0.9474 - val_loss: 0.1734 - val_accuracy: 0.9443\n","\n","Epoch 00009: val_accuracy did not improve from 0.94656\n","\n","Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Epoch 10/50\n","192/192 [==============================] - 598s 3s/step - loss: 0.1763 - accuracy: 0.9489 - val_loss: 0.3532 - val_accuracy: 0.9255\n","\n","Epoch 00010: val_accuracy did not improve from 0.94656\n","Epoch 11/50\n","192/192 [==============================] - 597s 3s/step - loss: 0.1582 - accuracy: 0.9557 - val_loss: 0.1988 - val_accuracy: 0.9254\n","\n","Epoch 00011: val_accuracy did not improve from 0.94656\n","Epoch 12/50\n","192/192 [==============================] - 597s 3s/step - loss: 0.1478 - accuracy: 0.9591 - val_loss: 0.1314 - val_accuracy: 0.9204\n","\n","Epoch 00012: val_accuracy did not improve from 0.94656\n","\n","Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","Epoch 13/50\n","192/192 [==============================] - 598s 3s/step - loss: 0.1407 - accuracy: 0.9612 - val_loss: 0.1185 - val_accuracy: 0.9298\n","\n","Epoch 00013: val_accuracy did not improve from 0.94656\n","Epoch 14/50\n","192/192 [==============================] - 598s 3s/step - loss: 0.1409 - accuracy: 0.9615 - val_loss: 0.1959 - val_accuracy: 0.9328\n","\n","Epoch 00014: val_accuracy did not improve from 0.94656\n","Epoch 15/50\n","192/192 [==============================] - 599s 3s/step - loss: 0.1324 - accuracy: 0.9646 - val_loss: 0.1690 - val_accuracy: 0.9251\n","\n","Epoch 00015: val_accuracy did not improve from 0.94656\n","\n","Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","Epoch 00015: early stopping\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kj7Bk_poV97Q","colab_type":"text"},"source":["#define a list of test image chunks \n"]},{"cell_type":"code","metadata":{"id":"JqdvLZbJJ5Qi","colab_type":"code","colab":{}},"source":["\"\"\"\n","This script takes a list of scene ids and creates a file that can be used as input for a segnet model\n","@param string chunk_dir: The abspath base directory where each set of chunks for a scene has its own dir named with its sceneID\n","@param list scene_ids: A list of sceneIDs that exist in the chunk_dir. The chunks of these scenes will be used in the file.\n","@param string out_path: The abspath where the resulting file should be saved.\n","@return int lines_written: the total number of lines (corresponding to a data and label chunk path) in the file.\n","file format:\n","/path/to/scene_chunk.npy,/path/to/scene_chunk_label.npy\n","/path/to/scene_chunk.npy,/path/to/scene_chunk_label.npy\n","/path/to/scene_chunk.npy,/path/to/scene_chunk_label.npy\n","...\n","\"\"\"\n","\n","import os\n","\n","def make_segnet_input_file(chunk_dir, scene_ids, out_path):\n","    existing_scenes = [i for i in os.listdir(chunk_dir) if os.path.isdir(os.path.join(chunk_dir, i))]\n","    # filter out ids that don't exist in the given dir\n","    scene_ids = [i for i in scene_ids if i in existing_scenes]\n","    print(scene_ids)\n","\n","    lines_to_write = []\n","\n","    for i in scene_ids:\n","        scene_dir = os.path.join(chunk_dir, i)\n","        for j in os.listdir(scene_dir):\n","            if j[-9:] != \"label.npy\":\n","                data_path = os.path.join(scene_dir, j)\n","                file_split = os.path.splitext(j)\n","                label_path = os.path.join(scene_dir, file_split[0] + \"_label\" + file_split[1])\n","\n","                lines_to_write.append(\"{},{}\\n\".format(data_path, label_path))\n","\n","    with open(out_path, 'w+') as output:\n","        output.writelines(lines_to_write)\n","\n","    return len(lines_to_write)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"az-Vvf86WQ78","colab_type":"text"},"source":["# Simple script to convert space-delimited chunk-path files to csv for easier file loading.\n","## Old file formats are still available in the metadata directory, but .csv equivalents should be used from now on. This script probably shouldn't been needed again.\n"]},{"cell_type":"code","metadata":{"id":"0disMicfWTZc","colab_type":"code","colab":{}},"source":["import csv\n","metadata_path = \"/content/drive/My Drive/Metadata\"\n","image_files = [i for i in os.listdir(metadata_path) if \".txt\" in i]\n","for i in image_files:\n","    file_name, extension = os.path.splitext(i)\n","    file_path = os.path.join(metadata_path, i)\n","    with open(file_path, 'r') as read_file:\n","        lines = [i[:-1].split(\" \") for i in read_file.readlines() if i]\n","    lines = [[f\"{i[0]} {i[1]}\", f\"{i[2]} {i[3]}\"] for i in lines]\n","\n","    with open(os.path.join(metadata_path, file_name + \".csv\"), 'w') as write_file:\n","        writer = csv.writer(write_file)\n","        writer.writerows(lines)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JM5D3eK4uzSU","colab_type":"code","outputId":"788ac7b4-6482-4580-db06-de5e5a9e1f9b","executionInfo":{"status":"error","timestamp":1589302590191,"user_tz":240,"elapsed":730,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":437}},"source":["metadata_file = [i for i in os.listdir(metadata_path) if \".csv\" in i][0]\n","print(metadata_file)\n","test_img_path = os.path.join(metadata_path, metadata_file)\n","\n","with open(test_img_path) as f:\n","    reader = csv.reader(f)\n","    data = next(reader)\n","\n","print(data[0])\n","print(os.path.isfile(data[0]))\n","\n","test_img = next(data_loader.image_segmentation_generator(data[0], data[1], 1, 2, 512, 512, 512, 512,))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["train.csv\n","/content/drive/My Drive/uncompressed_stacked_chunks/LC80651102015019LGN00/chunk_13_12.npy\n","True\n"],"name":"stdout"},{"output_type":"error","ename":"NotADirectoryError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m<ipython-input-53-0f7f13cc9ca1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mtest_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_segmentation_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_segmentation/data_utils/data_loader.py\u001b[0m in \u001b[0;36mimage_segmentation_generator\u001b[0;34m(images_path, segs_path, batch_size, n_classes, input_height, input_width, output_height, output_width, do_augment, augmentation_name)\u001b[0m\n\u001b[1;32m    193\u001b[0m                                  augmentation_name=\"aug_all\"):\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m     \u001b[0mimg_seg_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pairs_from_paths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegs_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_seg_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mzipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_seg_pairs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_segmentation/data_utils/data_loader.py\u001b[0m in \u001b[0;36mget_pairs_from_paths\u001b[0;34m(images_path, segs_path, ignore_non_matching)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0msegmentation_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdir_entry\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_entry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_entry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mACCEPTABLE_IMAGE_FORMATS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/content/drive/My Drive/uncompressed_stacked_chunks/LC80651102015019LGN00/chunk_13_12.npy'"]}]}]}
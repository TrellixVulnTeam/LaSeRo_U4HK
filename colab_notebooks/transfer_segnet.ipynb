{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transfer_segnet.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BZ80yyThVsON","colab_type":"text"},"source":["#Configuration Parameters"]},{"cell_type":"code","metadata":{"id":"AKJ0WYEK39xn","colab_type":"code","outputId":"419ca0f0-b771-466e-b96f-c719e5728e64","executionInfo":{"status":"ok","timestamp":1590431555437,"user_tz":240,"elapsed":433,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":55}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"qWRDYCBmLAOq","colab_type":"code","outputId":"d275823a-16bc-45e4-f922-a7cca756741f","executionInfo":{"status":"ok","timestamp":1590431557028,"user_tz":240,"elapsed":2014,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import sys\n","import os\n","import argparse\n","import csv\n","\n","import imageio\n","import numpy as np\n","import pandas as pd\n","\n","from keras.utils import multi_gpu_model, to_categorical\n","from keras.layers import Activation,Input\n","from keras.models import Model\n","from keras.applications.vgg16 import VGG16\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger\n","from tensorflow import convert_to_tensor\n","\n","sys.path.append(\"/content/drive/My Drive/tf-keras-SegNet\")\n","from model import segnet\n","sys.path.append('/content/drive/My Drive')\n","from lasero.utils import training"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"n4k2qGbmHZ47","colab_type":"code","colab":{}},"source":["base_dir = \"/content/drive/My Drive/\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oy2LMxNpHslq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":109},"outputId":"2fdbb9c1-0b57-4c75-b9a1-867ff0af0628","executionInfo":{"status":"ok","timestamp":1590431557031,"user_tz":240,"elapsed":1927,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}}},"source":["session_name = \"transfer_burjobands_lr_0.001\"\n","session_paths = training.create_session_paths(session_name)\n","for i in session_paths:\n","    print(session_paths[i])"],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/models/transfer_burjobands_lr_0.001/transfer_burjobands_lr_0.001.h5\n","/content/drive/My Drive/models/transfer_burjobands_lr_0.001/history.json\n","/content/drive/My Drive/models/transfer_burjobands_lr_0.001/logs.csv\n","/content/drive/My Drive/models/transfer_burjobands_lr_0.001/config.json\n","/content/drive/My Drive/models/transfer_burjobands_lr_0.001/classification_report.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M9idtsPKSejQ","colab_type":"code","colab":{}},"source":["def get_image_list(metadata_file_path):\n","    with open(metadata_file_path, 'r') as f:\n","        return [i for i in csv.reader(f) if i]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"euVM0pt-w0Xs","colab_type":"code","colab":{}},"source":["model_path = session_paths[\"model\"]\n","\n","metadata_path = os.path.join(base_dir, \"Metadata\")\n","dataset = \"one_percent\"\n","training_set_path = os.path.join(metadata_path, f'{dataset}_train.csv')\n","val_set_path = os.path.join(metadata_path, f'{dataset}_val.csv')\n","\n","bands = [1, 4, 8] # number of bands\n","\n","# if 'none', transfer weights cells should be skipped\n","weights = 'imagenet'\n","\n","num_classes = 2\n","\n","loss_function = 'categorical_crossentropy'\n","learning_rate = 0.001\n","optimizer = Adam(learning_rate=learning_rate)\n","\n","batch_size = 4\n","epochs = 50\n","\n","metrics = ['accuracy', 'loss', 'val_loss', 'val_accuracy']\n","stop_monitor_metric = \"val_loss\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUzeMcdZsKPM","colab_type":"code","colab":{}},"source":["lr_monitor_metric = 'val_loss'\n","factor = 0.5\n","lr_patience = 3\n","min_lr = 0.0001\n","\n","reduce_lr = ReduceLROnPlateau(monitor=lr_monitor_metric,\n","                              factor=factor,\n","                              patience=lr_patience,\n","                              verbose=1,\n","                              mode='auto',\n","                              min_lr=min_lr)\n","\n","stop_monitor_metric = 'val_loss'\n","stop_patience = 9\n","\n","early_stopper = EarlyStopping(monitor=stop_monitor_metric,\n","                              patience=stop_patience,\n","                              verbose=1,\n","                              mode='auto')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BLYMq3_kq9RJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":74},"outputId":"7583e960-a591-4386-ec21-68f47002b680","executionInfo":{"status":"ok","timestamp":1590431693359,"user_tz":240,"elapsed":249,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}}},"source":["session_manager = training.SessionManager(base_dir)\n","input_component = session_manager.build_input_components(dataset, bands, weights)\n","\n","opt_component = session_manager.build_opt_components(optimizer.__class__.__name__, loss_function, learning_rate)\n","\n","training_components = session_manager.build_training_components(batch_size, epochs)\n","lr_monitor_components = session_manager.build_lr_monitor_components(lr_monitor_metric, factor, lr_patience, min_lr)\n","stop_monitor_components = session_manager.build_stop_components(stop_monitor_metric, stop_patience)\n","\n","model_prefix = training_components + lr_monitor_components + stop_monitor_components\n","dir_tree = os.path.join(base_dir, 'models', input_component, opt_component, model_prefix)\n","print(dir_tree)\n","test = session_manager.parse_component()\n","print(test)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/models/data_set=one_percent_bands=1-4-8-_weights=imagenet/opt=Adam_loss=categorical_crossentropy_lr=0.001/batch=4_epochs=50_lrmonitor=val_loss_factor=0.5_patience=3_min=0.0001_stop_monitor=val_loss_patience=9\n","{'batch': '4', 'epochs': '50_'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5DrG1uCepcnS","colab_type":"code","colab":{}},"source":["training_set_list = training.get_image_list(training_set_path)\n","val_set_list = training.get_image_list(val_set_path)\n","training_set_size = len(training_set_list)\n","val_set_size = len(val_set_list)\n","\n","image_shape = (512, 512, len(bands))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jS01ZdNVDXjJ","colab_type":"text"},"source":["# Transfer weights of matching layers from image-net trained vgg16 to segnet"]},{"cell_type":"code","metadata":{"id":"qtQn_aCnaDsB","colab_type":"code","outputId":"5f276f53-05c9-4c36-90b9-ad515fd087dc","executionInfo":{"status":"ok","timestamp":1589992273232,"user_tz":240,"elapsed":264,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["segnet_model = segnet(image_shape, num_classes)\n","if weights != 'none':\n","    vgg_model = VGG16(include_top=False, weights=weights, input_shape=image_shape, classes=num_classes)\n","    seg_layer_names = [i for i in segnet_model.layers if \"conv\" in i.name]\n","    vgg_layer_names = [i for i in vgg_model.layers if \"conv\" in i.name]\n","    \n","    transferable_layer_names = {}\n","    for i in range(len(vgg_layer_names)):\n","        transferable_layer_names[seg_layer_names[i].name] = vgg_layer_names[i]\n","    \n","    layer_count = 0\n","    for i in segnet_model.layers:\n","        try:\n","            i.set_weights(transferable_layer_names[i.name].get_weights())\n","            layer_count += 1\n","        except KeyError:\n","            pass\n","    \n","    print(layer_count)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["13\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VmG7f6JdwXx_","colab_type":"text"},"source":["# Custom Generator"]},{"cell_type":"code","metadata":{"id":"55indsfD1s5J","colab_type":"code","colab":{}},"source":["def data_gen(metadata_file_path, bands, batch_size):\n","    image_list = np.asarray(get_image_list(metadata_file_path))\n","    np.random.seed(1)\n","    np.random.shuffle(image_list)\n","\n","    band_normalization_map = []\n","    counter = 0\n","\n","    total_steps = image_list.shape[0] // batch_size\n","    while True:\n","        step_start = counter * batch_size\n","        step_end = step_start + batch_size\n","        images = []\n","        masks = []\n","        for j in range(step_start, step_end):\n","            images.append(np.load(image_list[j, 0])[:,:,bands])\n","            masks.append(np.load(image_list[j, 1]))\n","\n","        y = to_categorical(np.array(masks), 2)\n","        yield np.array(images) / 65535, y.reshape((batch_size, y.shape[1] * y.shape[2], y.shape[3]))\n","\n","        counter +=1\n","\n","        if counter >= total_steps:\n","            counter = 0\n","            np.random.shuffle(image_list)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WlE-0IF4Wn9g","colab_type":"code","colab":{}},"source":["train_df = pd.read_csv(training_set_path)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h2NZIihQWBxg","colab_type":"text"},"source":["#Training model \n"]},{"cell_type":"code","metadata":{"id":"SMKEnOm3E8f7","colab_type":"code","outputId":"0bdeaebf-d21f-4092-af2d-aafe2d11b38d","executionInfo":{"status":"ok","timestamp":1589914453144,"user_tz":240,"elapsed":9431505,"user":{"displayName":"Samuel Elkind","photoUrl":"","userId":"14273351274395620639"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["train_data = data_gen(training_set_path, bands, batch_size)\n","val_data = data_gen(val_set_path, bands, batch_size)\n","\n","segnet_model.compile(optimizer=optimizer, loss=loss_function, metrics=metrics)\n","\n","save_model_path, model_file = os.path.split(session_paths[\"model\"])\n","save_model_file, model_ext = os.path.splitext(model_file)\n","save_model_prefix = os.path.join(save_model_path, save_model_file)\n","\n","accuracy_checkpoint = ModelCheckpoint(f'{save_model_prefix}_val_accuracy.h5',\n","                             monitor='val_accuracy',\n","                             verbose=1,\n","                             save_best_only=True,\n","                             mode='auto')\n","\n","loss_checkpoint = ModelCheckpoint(f'{save_model_prefix}_val_loss.h5',\n","                             monitor='val_accuracy',\n","                             verbose=1,\n","                             save_best_only=True,\n","                             mode='auto')\n","\n","# concatenation of save path is needed here to save model name dynamically by epoch\n","checkpoint = ModelCheckpoint(save_model_prefix + \"_epoch{epoch:02d}.h5\",\n","                             period=5,\n","                             save_weights_only=False,\n","                             save_best_only=False)\n","\n","csv_logger = CSVLogger(session_paths[\"logs\"])\n","\n","callbacks_list = [accuracy_checkpoint, loss_checkpoint, checkpoint, reduce_lr, csv_logger, early_stopper]\n","\n","hist = segnet_model.fit(train_data,\n","                        steps_per_epoch=training_set_size // batch_size,\n","                        epochs=epochs,\n","                        validation_data=val_data,\n","                        validation_steps=val_set_size // batch_size,\n","                        verbose=1,\n","                        callbacks=callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["single GPU in use\n","Epoch 1/50\n","1344/1344 [==============================] - 4588s 3s/step - loss: 0.3296 - accuracy: 0.9747 - val_loss: 2.8681 - val_accuracy: 0.6247\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.62467, saving model to /content/drive/My Drive/models/transfer_burjobands_lr_0.001/transfer_burjobands_lr_0.001_val_accuracy.h5\n","\n","Epoch 00001: val_loss improved from inf to 2.86814, saving model to /content/drive/My Drive/models/transfer_burjobands_lr_0.001/transfer_burjobands_lr_0.001_val_loss.h5\n","Epoch 2/50\n","1344/1344 [==============================] - 3187s 2s/step - loss: 0.1016 - accuracy: 0.9889 - val_loss: 0.0774 - val_accuracy: 0.9907\n","\n","Epoch 00002: val_accuracy improved from 0.62467 to 0.99072, saving model to /content/drive/My Drive/models/transfer_burjobands_lr_0.001/transfer_burjobands_lr_0.001_val_accuracy.h5\n","\n","Epoch 00002: val_loss improved from 2.86814 to 0.07741, saving model to /content/drive/My Drive/models/transfer_burjobands_lr_0.001/transfer_burjobands_lr_0.001_val_loss.h5\n","Epoch 3/50\n","1344/1344 [==============================] - 3012s 2s/step - loss: 0.0557 - accuracy: 0.9899 - val_loss: 0.1241 - val_accuracy: 0.9923\n","\n","Epoch 00003: val_accuracy improved from 0.99072 to 0.99234, saving model to /content/drive/My Drive/models/transfer_burjobands_lr_0.001/transfer_burjobands_lr_0.001_val_accuracy.h5\n","\n","Epoch 00003: val_loss did not improve from 0.07741\n","Epoch 4/50\n","1344/1344 [==============================] - 3203s 2s/step - loss: 0.0386 - accuracy: 0.9906 - val_loss: 0.0178 - val_accuracy: 0.9924\n","\n","Epoch 00004: val_accuracy improved from 0.99234 to 0.99239, saving model to /content/drive/My Drive/models/transfer_burjobands_lr_0.001/transfer_burjobands_lr_0.001_val_accuracy.h5\n","\n","Epoch 00004: val_loss improved from 0.07741 to 0.01781, saving model to /content/drive/My Drive/models/transfer_burjobands_lr_0.001/transfer_burjobands_lr_0.001_val_loss.h5\n","Epoch 5/50\n","1344/1344 [==============================] - 3063s 2s/step - loss: 0.0314 - accuracy: 0.9917 - val_loss: 0.0428 - val_accuracy: 0.9923\n","\n","Epoch 00005: val_accuracy did not improve from 0.99239\n","\n","Epoch 00005: val_loss did not improve from 0.01781\n","Epoch 6/50\n","1344/1344 [==============================] - 2988s 2s/step - loss: 0.0286 - accuracy: 0.9913 - val_loss: 0.0386 - val_accuracy: 0.9928\n","\n","Epoch 00006: val_accuracy improved from 0.99239 to 0.99280, saving model to /content/drive/My Drive/models/transfer_burjobands_lr_0.001/transfer_burjobands_lr_0.001_val_accuracy.h5\n","\n","Epoch 00006: val_loss did not improve from 0.01781\n","Epoch 7/50\n","1344/1344 [==============================] - 3449s 3s/step - loss: 0.0266 - accuracy: 0.9921 - val_loss: 0.1281 - val_accuracy: 0.9923\n","\n","Epoch 00007: val_accuracy did not improve from 0.99280\n","\n","Epoch 00007: val_loss did not improve from 0.01781\n","\n","Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","Epoch 8/50\n","1344/1344 [==============================] - 3929s 3s/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.0581 - val_accuracy: 0.9925\n","\n","Epoch 00008: val_accuracy did not improve from 0.99280\n","\n","Epoch 00008: val_loss did not improve from 0.01781\n","Epoch 9/50\n","1344/1344 [==============================] - 3327s 2s/step - loss: 0.0221 - accuracy: 0.9935 - val_loss: 0.0236 - val_accuracy: 0.9931\n","\n","Epoch 00009: val_accuracy improved from 0.99280 to 0.99307, saving model to /content/drive/My Drive/models/transfer_burjobands_lr_0.001/transfer_burjobands_lr_0.001_val_accuracy.h5\n","\n","Epoch 00009: val_loss did not improve from 0.01781\n","Epoch 10/50\n","1344/1344 [==============================] - 3193s 2s/step - loss: 0.0220 - accuracy: 0.9932 - val_loss: 0.0213 - val_accuracy: 0.9925\n","\n","Epoch 00010: val_accuracy did not improve from 0.99307\n","\n","Epoch 00010: val_loss did not improve from 0.01781\n","\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","Epoch 11/50\n"," 522/1344 [==========>...................] - ETA: 25:53 - loss: 0.0187 - accuracy: 0.9945"],"name":"stdout"}]}]}
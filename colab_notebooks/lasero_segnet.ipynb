{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"model_SegNet_bands_all_data_1percent.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"BZ80yyThVsON","colab_type":"text"},"source":["#Configuration Parameters"]},{"cell_type":"code","metadata":{"id":"euVM0pt-w0Xs","colab_type":"code","colab":{}},"source":["training_set_path='/content/drive/My Drive/Metadata/one_percent_train.txt'\n","val_set_path='/content/drive/My Drive/Metadata/one_percent_val.txt'\n","test_set_path='/content/drive/My Drive/Metadata/one_percent_test.txt'\n","model_path='/content/drive/My Drive/models/one_percent/'\n","\n","n_splits = 1\n","set_info={\"allBands\":[0,1,2,3,4,5,6,7,8,9]} # number of bands\n","\n","num_classes=2\n","image_shape=(512,512,10)\n","padding=((0,0),(0,0))\n","batch_size=5\n","epochs=50\n","learning_rate= 0.02\n","\n","training_set_size=770\n","val_set_size=100\n","test_set_size=100\n","# optimizer='sgd'\n","loss_function='categorical_crossentropy'\n","metrics=['accuracy']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gGoxYk5zV2BY","colab_type":"text"},"source":["#Creating encoding, decoding and max pooling layers\n"]},{"cell_type":"code","metadata":{"id":"yP4Xqz1UzR2_","colab_type":"code","colab":{}},"source":["from keras.layers import Activation,BatchNormalization,Conv2D\n","from keras.engine.topology import Layer\n","import keras.backend.tensorflow_backend as K\n","from keras.optimizers import Adam, SGD\n","\n","class MaxPoolingWithIndices(Layer):\n","    def __init__(self, pool_size,strides,padding='SAME',**kwargs):\n","        super(MaxPoolingWithIndices, self).__init__(**kwargs)\n","        self.pool_size=pool_size\n","        self.strides=strides\n","        self.padding=padding\n","        return\n","    def call(self,x):\n","        pool_size=self.pool_size\n","        strides=self.strides\n","        if isinstance(pool_size,int):\n","            ps=[1,pool_size,pool_size,1]\n","        else:\n","            ps=[1,pool_size[0],pool_size[1],1]\n","        if isinstance(strides,int):\n","            st=[1,strides,strides,1]\n","        else:\n","            st=[1,strides[0],strides[1],1]\n","        output1,output2=K.tf.nn.max_pool_with_argmax(x,ps,st,self.padding)\n","        return [output1,output2]\n","    def compute_output_shape(self, input_shape):\n","        if isinstance(self.pool_size,int):\n","            output_shape=(input_shape[0],input_shape[1]//self.pool_size,input_shape[2]//self.pool_size,input_shape[3])\n","        else:\n","            output_shape=(input_shape[0],input_shape[1]//self.pool_size[0],input_shape[2]//self.pool_size[1],input_shape[3])\n","        return [output_shape,output_shape]\n","\n","\n","class UpSamplingWithIndices(Layer):\n","    def __init__(self, **kwargs):\n","        super(UpSamplingWithIndices, self).__init__(**kwargs)\n","        return\n","    def call(self,x):\n","        argmax=K.cast(K.flatten(x[1]),'int32')\n","        max_value=K.flatten(x[0])\n","        with K.tf.variable_scope(self.name):\n","            input_shape=K.shape(x[0])\n","            batch_size=input_shape[0]\n","            image_size=input_shape[1]*input_shape[2]*input_shape[3]\n","            output_shape=[input_shape[0],input_shape[1]*2,input_shape[2]*2,input_shape[3]]\n","            indices_0=K.flatten(K.tf.matmul(K.reshape(K.tf.range(batch_size),(batch_size,1)),K.ones((1,image_size),dtype='int32')))\n","            indices_1=argmax%(image_size*4)//(output_shape[2]*output_shape[3])\n","            indices_2=argmax%(output_shape[2]*output_shape[3])//output_shape[3]\n","            indices_3=argmax%output_shape[3]\n","            indices=K.tf.stack([indices_0,indices_1,indices_2,indices_3])\n","            output=K.tf.scatter_nd(K.transpose(indices),max_value,output_shape)\n","            return output\n","    def compute_output_shape(self, input_shape):\n","        return input_shape[0][0],input_shape[0][1]*2,input_shape[0][2]*2,input_shape[0][3]\n","\n","def CompositeConv(inputs,num_layers,num_features):\n","    output=inputs\n","    if isinstance(num_features,int):\n","        for i in range(num_layers):\n","            output=Conv2D(num_features,(7,7),padding='same')(output)\n","            output=BatchNormalization(axis=3)(output)\n","            output=Activation('relu')(output)\n","        return output\n","    for i in range(num_layers):\n","        output=Conv2D(num_features[i],(7,7),padding='same')(output)\n","        output=BatchNormalization(axis=3)(output)\n","        output=Activation('relu')(output)\n","    return output\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WRkcpJXhV5XD","colab_type":"text"},"source":["#Creating SegNet model\n"]},{"cell_type":"code","metadata":{"id":"BXX_mRWz1gDQ","colab_type":"code","colab":{}},"source":["from keras.models import Model\n","from keras.layers import Activation,Input,ZeroPadding2D,Cropping2D\n","\n","\n","def create_model():\n","    inputs=Input(shape=image_shape)\n","\n","    x = ZeroPadding2D(padding)(inputs)\n","\n","    x=CompositeConv(x,2,64)\n","    x,argmax1=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","    \n","    x=CompositeConv(x,2,64)\n","    x,argmax2=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","    \n","    x=CompositeConv(x,3,64)\n","    x,argmax3=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","    x=CompositeConv(x,3,64)\n","    x,argmax4=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","    x=CompositeConv(x,3,64)\n","    x,argmax5=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n","\n","    x=UpSamplingWithIndices()([x,argmax5])\n","    x=CompositeConv(x,3,64)\n","\n","    x=UpSamplingWithIndices()([x,argmax4])\n","    x=CompositeConv(x,3,64)\n","\n","    x=UpSamplingWithIndices()([x,argmax3])\n","    x=CompositeConv(x,3,64)\n","\n","    x=UpSamplingWithIndices()([x,argmax2])\n","    x=CompositeConv(x,2,64)\n","    \n","    x=UpSamplingWithIndices()([x,argmax1])\n","    x=CompositeConv(x,2,[64,num_classes])\n","\n","    x=Activation('softmax')(x)\n","\n","    y=Cropping2D(padding)(x)\n","    my_model=Model(inputs=inputs,outputs=y)\n","    \n","    return my_model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oF4kjSrmV7zt","colab_type":"text"},"source":["#Read training image chunks in batches \n"]},{"cell_type":"code","metadata":{"id":"_XmrvXys1i8p","colab_type":"code","colab":{}},"source":["import imageio\n","import numpy as np\n","from keras.utils import to_categorical\n","\n","\n","def read_image_batch(image_list, batch_size, channel_list):\n","    while True:\n","        l=len(image_list)\n","        num_batch=l//batch_size\n","        if num_batch*batch_size<l:\n","            num_batch+=1\n","        for i in range(num_batch):\n","            batch_set=image_list[batch_size*i:min(batch_size*(i+1),l),:]\n","            batch_set=[batch_set[bs] for bs in range(len(batch_set))]\n","            X=np.array([np.load(line[0][0:]) for line in batch_set])\n","            labels=np.array([np.load(line[1][0:]) for line in batch_set])\n","            y=to_categorical(labels,num_classes)\n","            X = X[:, :, :, channel_list]\n","            yield tuple((X, y))\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h2NZIihQWBxg","colab_type":"text"},"source":["#Training model \n"]},{"cell_type":"code","metadata":{"id":"55indsfD1s5J","colab_type":"code","outputId":"8f6cefb4-4d06-4f8d-d009-5155c51d9e38","executionInfo":{"status":"ok","timestamp":1573940321062,"user_tz":300,"elapsed":4395236,"user":{"displayName":"whereare therocks","photoUrl":"","userId":"11641855154344275890"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import argparse\n","from keras.utils import multi_gpu_model\n","from keras.models import Model\n","from keras.layers import Activation,Input\n","import os\n","\n","def getSubsets(data_path, set_info, subset_size):\n","  image_list=[]\n","  with open(data_path,\"r\") as f:\n","    for line in f.readlines():\n","      arr=[]\n","      str_array=line.split(\" \")\n","      arr.append(str_array[0]+\" \"+str_array[1])\n","      arr.append(str_array[2]+\" \"+str_array[3][:-1])\n","      image_list.append(arr)\n","     \n","  image_list = np.asarray(image_list)\n","  np.random.seed(1)\n","  np.random.shuffle(image_list)\n","  data = []\n","  print(image_list.shape)\n","  jump = int(subset_size - ((subset_size*n_splits)-image_list.shape[0])/2)\n","  offset = image_list.shape[0]\n","  if n_splits>1:\n","      offset = image_list.shape[0]-subset_size\n","  for i in range(0, offset, jump):\n","      subset = image_list[i: i+subset_size,]\n","      print(subset.shape)\n","      for key, value in set_info.items():        \n","          data.append(read_image_batch(subset, batch_size, value))\n","  return np.asarray(data)\n","            \n","\n","def main(args):\n","    train_data = getSubsets(training_set_path, set_info, training_set_size)\n","    val_data = getSubsets(val_set_path, set_info, val_set_size)\n","  \n","    key=0\n","    for i in range(0, len(train_data)):\n","      my_model=create_model()\n","      my_model.compile(optimizer=args['opt'],loss=loss_function,metrics=metrics)\n","      if args['resume']:\n","            latest_model = args[\"load\"]+\"_best_lr_\"+str(learning_rate)\n","            print(\"Last Model picked up: \" + latest_model) \n","            my_model.load_weights(model_path+latest_model)\n","      min_loss = 1.0\n","      for j in range(11,epochs):\n","        hist = my_model.fit_generator(train_data[i],\n","                                steps_per_epoch=(training_set_size+1)//batch_size,\n","                                epochs=1,validation_data=val_data[i],\n","                                validation_steps=(val_set_size+1)//batch_size)\n","        val_loss = hist.history[\"val_loss\"]\n","        if j%5 == 0:\n","          my_model.save_weights(model_path+args['save']+\"_epoch\"+str(j)+\"_lr_\"+str(learning_rate));  \n","        if val_loss[0] < min_loss:\n","          min_loss = val_loss[0]\n","          my_model.save_weights(model_path+args['save']+\"_best_lr_\"+str(learning_rate))\n","        print(\"model fit epoch: \"+str(j))\n","        \n","\n","args = {\"save\": \"model_allBands\", \"resume\":False, \"load\": \"model_allBands\", \"opt\": SGD(lr=learning_rate)}\n","main(args)\n"],"execution_count":115,"outputs":[{"output_type":"stream","text":["(770, 2)\n","(770, 2)\n","(100, 2)\n","(100, 2)\n","Epoch 1/1\n","154/154 [==============================] - 238s 2s/step - loss: 0.4742 - acc: 0.8911 - val_loss: 0.3676 - val_acc: 0.9193\n","model fit epoch: 11\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.3281 - acc: 0.9284 - val_loss: 0.3085 - val_acc: 0.9198\n","model fit epoch: 12\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.2707 - acc: 0.9290 - val_loss: 0.2877 - val_acc: 0.9199\n","model fit epoch: 13\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.2417 - acc: 0.9291 - val_loss: 0.2752 - val_acc: 0.9198\n","model fit epoch: 14\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.2197 - acc: 0.9293 - val_loss: 0.2047 - val_acc: 0.9200\n","model fit epoch: 15\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.2009 - acc: 0.9313 - val_loss: 0.2462 - val_acc: 0.9200\n","model fit epoch: 16\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.1853 - acc: 0.9334 - val_loss: 0.1850 - val_acc: 0.9200\n","model fit epoch: 17\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.1747 - acc: 0.9340 - val_loss: 0.1991 - val_acc: 0.9201\n","model fit epoch: 18\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.1641 - acc: 0.9350 - val_loss: 0.1842 - val_acc: 0.9201\n","model fit epoch: 19\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.1549 - acc: 0.9358 - val_loss: 0.2002 - val_acc: 0.9201\n","model fit epoch: 20\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.1549 - acc: 0.9349 - val_loss: 0.1846 - val_acc: 0.9201\n","model fit epoch: 21\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.1410 - acc: 0.9368 - val_loss: 0.2092 - val_acc: 0.9201\n","model fit epoch: 22\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.1338 - acc: 0.9373 - val_loss: 0.1974 - val_acc: 0.9201\n","model fit epoch: 23\n","Epoch 1/1\n","154/154 [==============================] - 198s 1s/step - loss: 0.1280 - acc: 0.9379 - val_loss: 0.2080 - val_acc: 0.9201\n","model fit epoch: 24\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.1231 - acc: 0.9384 - val_loss: 0.1847 - val_acc: 0.9203\n","model fit epoch: 25\n","Epoch 1/1\n","154/154 [==============================] - 198s 1s/step - loss: 0.1191 - acc: 0.9389 - val_loss: 0.2222 - val_acc: 0.9201\n","model fit epoch: 26\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.1157 - acc: 0.9393 - val_loss: 0.2285 - val_acc: 0.9201\n","model fit epoch: 27\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.1125 - acc: 0.9396 - val_loss: 0.2081 - val_acc: 0.9202\n","model fit epoch: 28\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.1101 - acc: 0.9399 - val_loss: 0.2363 - val_acc: 0.9201\n","model fit epoch: 29\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.1076 - acc: 0.9402 - val_loss: 0.2346 - val_acc: 0.9201\n","model fit epoch: 30\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.1058 - acc: 0.9410 - val_loss: 0.2312 - val_acc: 0.9201\n","model fit epoch: 31\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.1020 - acc: 0.9482 - val_loss: 0.2149 - val_acc: 0.9204\n","model fit epoch: 32\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.0984 - acc: 0.9513 - val_loss: 0.2300 - val_acc: 0.9202\n","model fit epoch: 33\n","Epoch 1/1\n","154/154 [==============================] - 201s 1s/step - loss: 0.0963 - acc: 0.9517 - val_loss: 0.2332 - val_acc: 0.9202\n","model fit epoch: 34\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.0944 - acc: 0.9521 - val_loss: 0.2232 - val_acc: 0.9202\n","model fit epoch: 35\n","Epoch 1/1\n","154/154 [==============================] - 201s 1s/step - loss: 0.0931 - acc: 0.9523 - val_loss: 0.2178 - val_acc: 0.9203\n","model fit epoch: 36\n","Epoch 1/1\n","154/154 [==============================] - 200s 1s/step - loss: 0.0917 - acc: 0.9526 - val_loss: 0.2146 - val_acc: 0.9203\n","model fit epoch: 37\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.0901 - acc: 0.9529 - val_loss: 0.1909 - val_acc: 0.9209\n","model fit epoch: 38\n","Epoch 1/1\n","154/154 [==============================] - 198s 1s/step - loss: 0.0891 - acc: 0.9530 - val_loss: 0.1938 - val_acc: 0.9210\n","model fit epoch: 39\n","Epoch 1/1\n","154/154 [==============================] - 198s 1s/step - loss: 0.0881 - acc: 0.9532 - val_loss: 0.2179 - val_acc: 0.9203\n","model fit epoch: 40\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.0877 - acc: 0.9532 - val_loss: 0.2191 - val_acc: 0.9203\n","model fit epoch: 41\n","Epoch 1/1\n","154/154 [==============================] - 198s 1s/step - loss: 0.0867 - acc: 0.9535 - val_loss: 0.2195 - val_acc: 0.9203\n","model fit epoch: 42\n","Epoch 1/1\n","154/154 [==============================] - 198s 1s/step - loss: 0.0856 - acc: 0.9537 - val_loss: 0.2221 - val_acc: 0.9203\n","model fit epoch: 43\n","Epoch 1/1\n","154/154 [==============================] - 199s 1s/step - loss: 0.0846 - acc: 0.9539 - val_loss: 0.2235 - val_acc: 0.9203\n","model fit epoch: 44\n","Epoch 1/1\n","154/154 [==============================] - 197s 1s/step - loss: 0.0843 - acc: 0.9541 - val_loss: 0.2005 - val_acc: 0.9208\n","model fit epoch: 45\n","Epoch 1/1\n","154/154 [==============================] - 198s 1s/step - loss: 0.0838 - acc: 0.9548 - val_loss: 0.2134 - val_acc: 0.9204\n","model fit epoch: 46\n","Epoch 1/1\n","154/154 [==============================] - 197s 1s/step - loss: 0.0797 - acc: 0.9640 - val_loss: 0.1989 - val_acc: 0.9223\n","model fit epoch: 47\n","Epoch 1/1\n","154/154 [==============================] - 197s 1s/step - loss: 0.0730 - acc: 0.9760 - val_loss: 0.2132 - val_acc: 0.9219\n","model fit epoch: 48\n","Epoch 1/1\n","154/154 [==============================] - 197s 1s/step - loss: 0.0848 - acc: 0.9720 - val_loss: 0.2413 - val_acc: 0.9209\n","model fit epoch: 49\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Kj7Bk_poV97Q","colab_type":"text"},"source":["#define a list of test image chunks \n"]},{"cell_type":"code","metadata":{"id":"SpryaCe8Al5f","colab_type":"code","colab":{}},"source":["\n","test_names=[]\n","\n","with open(test_set_path,\"r\") as f:\n","  test_image_list=[]\n","  for line in f.readlines():\n","    arr=[]\n","    str_array=line.split(\" \")\n","    arr.append(str_array[0]+\" \"+str_array[1])\n","    arr.append(str_array[2]+\" \"+str_array[3][:-1])\n","    test_image_list.append(arr)\n","    test_names.append(line)\n","\n","test_image_list=np.asarray(test_image_list)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hZw0KDjFV_yk","colab_type":"text"},"source":["#read test chunks in batches using the list defined above \n"]},{"cell_type":"code","metadata":{"id":"my-pI2L4smKf","colab_type":"code","colab":{}},"source":["\n","import imageio\n","import numpy as np\n","from keras.utils import to_categorical\n","\n","def read_test_image_batch(image_list, batch_size, channel_list):\n","    while True:\n","        l=len(image_list)\n","        num_batch=l//batch_size\n","        if num_batch*batch_size<l:\n","            num_batch+=1\n","        for i in range(num_batch):\n","            batch_set=image_list[batch_size*i:min(batch_size*(i+1),l),:]\n","            batch_set=[batch_set[bs] for bs in range(len(batch_set))]\n","            X=np.array([np.load(line[0][0:]) for line in batch_set])\n","            labels=np.array([np.load(line[1][0:]) for line in batch_set])\n","            y=to_categorical(labels,num_classes)\n","            X = X[:, :, :, channel_list]\n","            yield tuple((X, y))\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AiB6Qm0oWE4m","colab_type":"text"},"source":["#testing model\n"]},{"cell_type":"code","metadata":{"id":"BW4Mjj1a-mY6","colab_type":"code","colab":{}},"source":["import argparse\n","from keras.models import Model\n","from keras.layers import Activation,Input\n","from scipy.stats import mode\n","import os\n","\n","\n","class_labels=[]\n","\n","\n","for i in os.listdir(model_path):\n","  if(i==\".ipynb_checkpoints\"):\n","    continue\n","\n","  key=0\n","  #if(key!=0):\n","  #   continue\n","\n","  print(model_path+i)\n","  my_model=create_model()\n","  my_model.compile(optimizer,loss=loss_function,metrics=metrics)\n","  my_model.load_weights(model_path+i)\n","  \n","  test_data=read_test_image_batch(test_image_list,batch_size,set_info[key])\n","  probs=my_model.predict(test_data,steps=(test_set_size+1)//batch_size)\n","  print(\"\\nprobs\")\n","  print(probs.shape)\n","  class_labels.append(probs.argmax(axis=-1))\n","\n","hist = np.histogram(class_labels[0])\n","class_labels=np.asarray(class_labels)\n","u,indices=np.unique(class_labels,return_inverse=True)\n","final_labels=u[np.argmax(np.apply_along_axis(np.bincount,0,indices.reshape(class_labels.shape),None,np.max(indices)+1),axis=0)]\n","\n","for i in range(test_set_size):\n","  line=test_names[i]\n","  print(line)\n","  str_array=line.split(\" \")\n","  scene_id=str_array[1][18:40]\n","  out_str=str_array[1][40:-4]+\"_output.npy\"\n","  print(out_str)\n","  np.save('/content/drive/My Drive/new_test_outputs_key_0/'+scene_id+out_str,final_labels[i])\n","  "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JqdvLZbJJ5Qi","colab_type":"code","colab":{}},"source":["\"\"\"\n","This script takes a list of scene ids and creates a file that can be used as input for a segnet model\n","@param string chunk_dir: The abspath base directory where each set of chunks for a scene has its own dir named with its sceneID\n","@param list scene_ids: A list of sceneIDs that exist in the chunk_dir. The chunks of these scenes will be used in the file.\n","@param string out_path: The abspath where the resulting file should be saved.\n","@return int lines_written: the total number of lines (corresponding to a data and label chunk path) in the file.\n","file format:\n","/path/to/scene_chunk.npy /path/to/scene_chunk_label.npy\n","/path/to/scene_chunk.npy /path/to/scene_chunk_label.npy\n","/path/to/scene_chunk.npy /path/to/scene_chunk_label.npy\n","...\n","\"\"\"\n","\n","import os\n","\n","def make_segnet_input_file(chunk_dir, scene_ids, out_path):\n","    existing_scenes = [i for i in os.listdir(chunk_dir) if os.path.isdir(os.path.join(chunk_dir, i))]\n","    # filter out ids that don't exist in the given dir\n","    scene_ids = [i for i in scene_ids if i in existing_scenes]\n","    print(scene_ids)\n","\n","    lines_to_write = []\n","\n","    for i in scene_ids:\n","        scene_dir = os.path.join(chunk_dir, i)\n","        for j in os.listdir(scene_dir):\n","            if j[-9:] != \"label.npy\":\n","                data_path = os.path.join(scene_dir, j)\n","                file_split = os.path.splitext(j)\n","                label_path = os.path.join(scene_dir, file_split[0] + \"_label\" + file_split[1])\n","\n","                lines_to_write.append(\"{} {}\\n\".format(data_path, label_path))\n","\n","    with open(out_path, 'w+') as output:\n","        output.writelines(lines_to_write)\n","\n","    return len(lines_to_write)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gNnhZ-CS3TEf","colab_type":"text"},"source":["#Mount Drive"]},{"cell_type":"code","metadata":{"id":"AKJ0WYEK39xn","colab_type":"code","outputId":"c35f0936-45e9-4ddd-ad27-f0a6e112aedb","executionInfo":{"status":"ok","timestamp":1573925855101,"user_tz":300,"elapsed":24470,"user":{"displayName":"Shubhangi Upasani","photoUrl":"","userId":"13744605831269149323"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZRSxxWvT-fpy","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
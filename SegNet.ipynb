{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SegNetCode_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "euVM0pt-w0Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!tar -xvzf LC82071142014003LGN00.tar\n",
        "\n",
        "training_set_path='SegNet/Landsat/train.txt'\n",
        "val_set_path='SegNet/Landsat/val.txt'\n",
        "test_set_path='SegNet/CamVid/test.txt'\n",
        "model_path='models/'\n",
        "\n",
        "num_classes=2\n",
        "image_shape=(512,512,10)\n",
        "padding=((0,0),(0,0))\n",
        "batch_size=5\n",
        "epochs=100\n",
        "training_set_size=153\n",
        "val_set_size=30\n",
        "test_set_size=233\n",
        "optimizer='sgd'\n",
        "loss_function='categorical_crossentropy'\n",
        "metrics=['accuracy']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP4Xqz1UzR2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Activation,BatchNormalization,Conv2D\n",
        "from keras.engine.topology import Layer\n",
        "#import keras.backend as K\n",
        "#import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as K\n",
        "\n",
        "class MaxPoolingWithIndices(Layer):\n",
        "    def __init__(self, pool_size,strides,padding='SAME',**kwargs):\n",
        "        super(MaxPoolingWithIndices, self).__init__(**kwargs)\n",
        "        self.pool_size=pool_size\n",
        "        self.strides=strides\n",
        "        self.padding=padding\n",
        "        return\n",
        "    def call(self,x):\n",
        "        pool_size=self.pool_size\n",
        "        strides=self.strides\n",
        "        if isinstance(pool_size,int):\n",
        "            ps=[1,pool_size,pool_size,1]\n",
        "        else:\n",
        "            ps=[1,pool_size[0],pool_size[1],1]\n",
        "        if isinstance(strides,int):\n",
        "            st=[1,strides,strides,1]\n",
        "        else:\n",
        "            st=[1,strides[0],strides[1],1]\n",
        "        output1,output2=K.tf.nn.max_pool_with_argmax(x,ps,st,self.padding)\n",
        "        return [output1,output2]\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if isinstance(self.pool_size,int):\n",
        "            output_shape=(input_shape[0],input_shape[1]//self.pool_size,input_shape[2]//self.pool_size,input_shape[3])\n",
        "        else:\n",
        "            output_shape=(input_shape[0],input_shape[1]//self.pool_size[0],input_shape[2]//self.pool_size[1],input_shape[3])\n",
        "        return [output_shape,output_shape]\n",
        "\n",
        "\n",
        "class UpSamplingWithIndices(Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(UpSamplingWithIndices, self).__init__(**kwargs)\n",
        "        return\n",
        "    def call(self,x):\n",
        "        argmax=K.cast(K.flatten(x[1]),'int32')\n",
        "        max_value=K.flatten(x[0])\n",
        "        with K.tf.variable_scope(self.name):\n",
        "            input_shape=K.shape(x[0])\n",
        "            batch_size=input_shape[0]\n",
        "            image_size=input_shape[1]*input_shape[2]*input_shape[3]\n",
        "            output_shape=[input_shape[0],input_shape[1]*2,input_shape[2]*2,input_shape[3]]\n",
        "            indices_0=K.flatten(K.tf.matmul(K.reshape(K.tf.range(batch_size),(batch_size,1)),K.ones((1,image_size),dtype='int32')))\n",
        "            indices_1=argmax%(image_size*4)//(output_shape[2]*output_shape[3])\n",
        "            indices_2=argmax%(output_shape[2]*output_shape[3])//output_shape[3]\n",
        "            indices_3=argmax%output_shape[3]\n",
        "            indices=K.tf.stack([indices_0,indices_1,indices_2,indices_3])\n",
        "            output=K.tf.scatter_nd(K.transpose(indices),max_value,output_shape)\n",
        "            return output\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0][0],input_shape[0][1]*2,input_shape[0][2]*2,input_shape[0][3]\n",
        "\n",
        "def CompositeConv(inputs,num_layers,num_features):\n",
        "    output=inputs\n",
        "    if isinstance(num_features,int):\n",
        "        for i in range(num_layers):\n",
        "            output=Conv2D(num_features,(7,7),padding='same')(output)\n",
        "            output=BatchNormalization(axis=3)(output)\n",
        "            output=Activation('relu')(output)\n",
        "        return output\n",
        "    for i in range(num_layers):\n",
        "        output=Conv2D(num_features[i],(7,7),padding='same')(output)\n",
        "        output=BatchNormalization(axis=3)(output)\n",
        "        output=Activation('relu')(output)\n",
        "    return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXX_mRWz1gDQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Activation,Input,ZeroPadding2D,Cropping2D\n",
        "#from custom_layers import MaxPoolingWithIndices,UpSamplingWithIndices,CompositeConv\n",
        "#import config as cf\n",
        "\n",
        "def create_model():\n",
        "    inputs=Input(shape=image_shape)\n",
        "\n",
        "    x = ZeroPadding2D(padding)(inputs)\n",
        "\n",
        "    x=CompositeConv(x,2,64)\n",
        "    x,argmax1=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n",
        "    \n",
        "    x=CompositeConv(x,2,64)\n",
        "    x,argmax2=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n",
        "    \n",
        "    x=CompositeConv(x,3,64)\n",
        "    x,argmax3=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n",
        "\n",
        "    x=CompositeConv(x,3,64)\n",
        "    x,argmax4=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n",
        "\n",
        "    x=CompositeConv(x,3,64)\n",
        "    x,argmax5=MaxPoolingWithIndices(pool_size=2,strides=2)(x)\n",
        "\n",
        "    x=UpSamplingWithIndices()([x,argmax5])\n",
        "    x=CompositeConv(x,3,64)\n",
        "\n",
        "    x=UpSamplingWithIndices()([x,argmax4])\n",
        "    x=CompositeConv(x,3,64)\n",
        "\n",
        "    x=UpSamplingWithIndices()([x,argmax3])\n",
        "    x=CompositeConv(x,3,64)\n",
        "\n",
        "    x=UpSamplingWithIndices()([x,argmax2])\n",
        "    x=CompositeConv(x,2,64)\n",
        "    \n",
        "    x=UpSamplingWithIndices()([x,argmax1])\n",
        "    x=CompositeConv(x,2,[64,num_classes])\n",
        "\n",
        "    x=Activation('softmax')(x)\n",
        "\n",
        "    y=Cropping2D(padding)(x)\n",
        "    my_model=Model(inputs=inputs,outputs=y)\n",
        "    \n",
        "    return my_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XmrvXys1i8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import imageio\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "#import config as cf\n",
        "\n",
        "def read_image_batch(data_path,batch_size):\n",
        "    while True:\n",
        "        image_list=open(data_path).readlines()\n",
        "        l=len(image_list)\n",
        "        \n",
        "        num_batch=l//batch_size\n",
        "        if num_batch*batch_size<l:\n",
        "            num_batch+=1\n",
        "        for i in range(num_batch):\n",
        "            batch_set=image_list[batch_size*i:min(batch_size*(i+1),l)]\n",
        "            batch_set=[bs.strip().split() for bs in batch_set]\n",
        "            #X=np.array([imageio.imread(line[0][1:]) for line in batch_set])\n",
        "            #labels=np.array([imageio.imread(line[1][1:]) for line in batch_set])\n",
        "            X=np.array([np.load(line[0][1:]) for line in batch_set])\n",
        "            labels=np.array([np.load(line[1][1:]) for line in batch_set])\n",
        "            y=to_categorical(labels,num_classes)\n",
        "           \n",
        "            yield tuple((X, y))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55indsfD1s5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "from keras.utils import multi_gpu_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation,Input\n",
        "#from custom_layers import MaxPoolingWithIndices,UpSamplingWithIndices,CompositeConv\n",
        "#import config as cf\n",
        "#from util import read_image_batch\n",
        "#from create_model import create_model\n",
        "\n",
        "def main(args):\n",
        "    my_model=create_model()\n",
        "    my_model.compile(optimizer,loss=loss_function,metrics=metrics)\n",
        "    \n",
        "    if args['resume']:\n",
        "        my_model.load_weights(model_path+args['load'])\n",
        "    \n",
        "    val_data=read_image_batch(val_set_path, batch_size)\n",
        "    train_data=read_image_batch(training_set_path,batch_size)\n",
        "    print(\"read image batch\")\n",
        "    my_model.fit_generator(train_data,\n",
        "                           steps_per_epoch=(training_set_size+1)//batch_size,\n",
        "                           epochs=epochs,validation_data=val_data,\n",
        "                           validation_steps=(val_set_size+1)//batch_size)\n",
        "    print(\"model fit\")\n",
        "    my_model.save_weights(model_path+args['save'])\n",
        "\n",
        "#parser = argparse.ArgumentParser()\n",
        "#parser.add_argument(\"--save\",default='my_model')\n",
        "#parser.add_argument(\"--resume\",action='store_true')\n",
        "#parser.add_argument(\"--load\",default='my_model')\n",
        "args = {\"save\": \"my_model\", \"resume\":False, \"load\": \"my_model\"}\n",
        "main(args)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}